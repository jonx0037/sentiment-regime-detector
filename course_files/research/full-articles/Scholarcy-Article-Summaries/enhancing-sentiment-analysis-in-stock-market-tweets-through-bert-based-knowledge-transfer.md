[[Cicekyurt_EnhancingSentimentAnalysisStockMarket_2025]]

# [Enhancing Sentiment Analysis in Stock Market Tweets Through BERT-Based Knowledge Transfer](https://doi.org/10.1007/s10614-025-10901-8)

## [[Emre Cicekyurt]]; [[Gokhan Bakal]]

## Abstract
Abstract One of the widely studied text classification efforts is sentiment analysis. It is a specific examination involving natural language processing and machine learning methods to understand semantic orientation from textual data. Working social media posts, such as tweets, for sentiment analysis, is quite common among researchers due to the speed of information dissemination. In this regard, forecasting stock market tweets is a widely studied research topic. Some studies have revealed a strong connection between sentiment and stock market performance, while others have not found any notable associations. The proposed work shows two distinct approaches to sentiment analysis over the stock market tweets. The first approach employs traditional machine learning algorithms, including logistic regression, random forest, and XGBoost. The second approach constructs deep learning (as a subfield of machine learning) models using LSTM and CNN algorithms to classify the test instances into positive, negative, or neutral classes through ten randomly shuffled data splits. In this study, the labeled data size is gradually increased utilizing a pre-trained model, FinBERT. It is exclusively employed to label unlabeled data instances to integrate them into the experiments. The goal is to monitor the effect of the additional newly-labeled examples on the sentiment analysis performance. The experiments showed that the average F1-score improved by 20% for the deep learning models and 17% for the machine learning models. In the end, the paper reveals a strong positive correlation between training data size and the classification performance of the experimental approaches.

## Key concepts
#finding/machine_learning; #machine_learning; #natural_language_processing; #finding/logistic_regression; #logistic_regression; #sentiment_analysis; #natural_language; #finding/stock_market; #stock_market; #deep_learning; #long_short_term_memory; #finding/random_forest; #random_forest

## Quote
> The study explores the use of BERT-based knowledge transfer to enhance sentiment analysis in stock market tweets, demonstrating a strong positive correlation between training data size and classification performance, with average F1-score improvements of 20% for deep learning models and 17% for machine learning models.

## Key points
- Text classification is an essential task since it enables the extraction of relevant information from vast amounts of text and can be applied to various domains for distinct purposes, including sentiment analysis, spam detection, and topic modeling
- The convolutional neural networks (CNNs) model outperformed the Long Short-Term Memory (LSTM) model, the CNN model did not achieve any better performances than the best-performing logistic regression and random forest models
- When we interpret the impact of the Deep learning (DL) experiments utilizing cumulatively more annotated instances, the LSTM model captured more discriminative contextual information than the CNN model when we introduced new samples
- Sentiment analysis stands as a pivotal research endeavor within the machine learning and data science fields, where it finds widespread applications across various domains, encompassing individual opinions on products or services to collective expressions in social media posts
- The optimal machine learning model, constructed using the random forest algorithm with unigram features and 40,000 new instances, achieved an F1 score of 69%, which outperforms the initial model’s F1 score of 54% in its best configuration. This noteworthy improvement of 15% in F1 score reaffirms the effectiveness of our approach, a result consistently observed across both traditional machine learning and deep learning model experiments
- Among the xgboost classifier experiments, again, the model using unigram feature space yielded the highest F1 score as opposed to the other feature space configurations
- One limitation lies in the reliance on labeled data, and the study’s focus on sentiment analysis may not capture the full spectrum of market dynamics


## Summary

### Introduction
The study focuses on sentiment analysis of stock market tweets, utilizing natural language processing and machine learning methods to understand semantic orientation from textual data.
The goal is to examine the effect of increasing the size of labeled data on the performance of sentiment analysis models.

### Methods
Two approaches are employed: traditional machine learning algorithms (logistic regression, random forest, and XGBoost) and deep learning models (LSTM and CNN).
A pre-trained model, FinBERT, is used to label unlabeled data instances, which are then incorporated into the experiments.
The results show that the average F1-score improved by 20% for the deep learning models and 17% for the machine learning models.

### Results
The study reveals a strong positive correlation between training data size and the classification performance of the experimental approaches.
The experiments demonstrate that using a pre-trained model to label unlabeled data can significantly boost classification performance, even in the absence of human annotators.
The findings suggest that sentiment analysis of stock market tweets can provide valuable insights into market trends and investor sentiment.

### NLP Techniques
Natural language processing (NLP) techniques are employed to extract meaningful features from raw text data.
Data preprocessing is crucial in NLP to improve model accuracy by cleaning the data before analysis.
Preprocessing steps include tokenization, lemmatization, and stop-word removal.
The dataset used in this study consists of 1,300 tweets and requires additional cleaning operations to remove unnecessary information.

### Machine Learning
Machine learning algorithms, including logistic regression, random forest, and xgboost, are used to build traditional machine learning models that predict tweet sentiment labels.
A TF-IDF vectorizer is used to convert textual data into a numerical matrix representation for training the models.
N-gram representations are also used to analyze the statistical properties of the text and understand the conveyed meaning.

### Deep Learning
Deep learning models, including convolutional neural networks (CNNs) and long short-term memory (LSTM) models, are used to capture complex non-linear relationships and abstract patterns in the data.
CNNs are effective in capturing local patterns and features in text, while LSTMs are designed to overcome vanishing and exploding gradient problems in traditional RNNs.
Non-linear activation functions, such as ReLU, are used to introduce non-linearity into the model's decision boundaries, allowing the models to learn hierarchical representations of the data.

### Models
The study utilizes various machine learning models, including logistic regression, random forest, xgboost, CNN, and LSTM, to classify financial tweet instances according to their contextual sentiment information.
The models are evaluated based on their performance, with the random forest model using unigram features achieving the highest F1 score.
The study also explores the use of pre-trained models, such as Fin-BERT, to improve the performance of the models.

### Performance
The performance of the models is evaluated using various metrics, including precision, recall, and F1 score.
The results show that increasing the number of new examples helps to boost the models' classification power, with the random forest model achieving an F1 score of 69% when using 40,000 new instances.
The study also finds that the traditional machine learning models perform better than the deep learning models, likely due to the short length of the tweet examples.

### Limitations
The study has several limitations, including its reliance on labeled data and its focus on sentiment analysis, which may not capture the full spectrum of market dynamics.
The effectiveness of the proposed approaches may vary across different market conditions, and external factors influencing sentiment expression could impact the generalizability of the models.
Additionally, the original data collection method may not be functional due to changes to Twitter's APIs.

### Future Work
The success of the proposed Bert-based approach can be confirmed by performing additional operations in the future.
Another potential future direction is exploring ensemble models or hybrid approaches that combine traditional machine learning algorithms with deep learning techniques, which might offer synergistic advantages.

### Data And Funding
The dataset used is available via the link: https://ieee-dataport.org/open-access/stock-market-tweets-data.
Open access funding was provided by the Scientific and Technological Research Council of Türkiye (TÜBİTAK).

### Publication Details
The article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution, and reproduction in any medium or format, as long as appropriate credit is given to the original authors and the source.
The article was written by E.
Cicekyurt and G.
Bakal, with G.
Bakal supervising the project and conceiving the original idea.


## Study subjects

### 45 companies
- Plus, they revealed that the sentiment of tweets was a significant predictor of stock price movements (Bacco et al, 2024; Gandhudi et al, 2024). ==Yet another relevant effort employed by [^Antweiler_2004_a]) examined the influence of Internet stock message boards on market movements, explicitly focusing on the 45 companies in the Dow Jones Industrial Average and the Dow Jones Internet Index==. They analyzed over 1.5 million messages posted on Yahoo! Finance and Raging Bull, using computational linguistics methods to measure the bullishness level

### 943672 tweets
- 3 Dataset &amp; Data Preprocessing. ==Between April 9th and July 16th, 2020, 943,672 tweets were obtained using hashtags such as #SPX500, references to the top 25 companies in the S&amp;P 500 index, and #stocks by Taborda et al (2021)==. Among these tweets, 1300 were annotated by manual efforts and labeled as positive (529), neutral (349), or negative (422)

## Data analysis
- #method/lstm_model
- #method/bert_model
- #method/logistic_regression
- #method/natural_language_toolkit
- #method/cnn_model
- #method/maximum_likelihood_estimation
- #method/dow_jones_internet_index

## Findings
- <mark class="fact">The experiments showed that the average F1-score improved by</mark> 20% for the <a class="keyword" href="https://en.wikipedia.org/wiki/Deep_learning" title="deep learning">deep learning</a> models and 17% for the <a class="keyword" href="https://en.wikipedia.org/wiki/machine_learning" title="machine learning">machine learning</a> models
- <mark class="fact">The study performed by Bollen et al</mark> (2011); Khafaga et al (2023) disclosed that Twitter posts could be used to understand the encoded sentiment and to predict <a class="keyword" href="https://en.wikipedia.org/wiki/stock_market" title="stock market">stock market</a> changes with an accuracy of 86%, where the dataset used consisted of over 2 million tweets and a subset of Dow Jones Industrial Average (<a class="keyword" href="#" title="Dow Jones Industrial Average">DJIA</a>) stocks
- The authors used a tweet dataset and stock prices from 2012 to 2013 and found no significant correlation between the sentiment of tweets and stock prices
- The authors used a dataset containing nine-month stock tweets and daily stock data and identified that their model could predict stock price movements with an accuracy range between 75% and 85%
- <mark class="claim">Among the xgboost classifier experiments, again, the model using unigram feature space yielded the highest F1 score as opposed to the other feature space configurations</mark>
- <mark class="claim">When the most successful models are considered regardless of the classifier type in each configuration where additional instances are cumulatively included, we achieved at least a 1% F1 score improvement</mark>
- <mark class="claim">Contrary to the best model, the lowest model achieved an F1 score of 45%</mark>
- Specifically, the optimal <a class="keyword" href="https://en.wikipedia.org/wiki/machine_learning" title="machine learning">machine learning</a> model, constructed using the <a class="keyword" href="https://en.wikipedia.org/wiki/random_forest" title="random forest">random forest</a> algorithm with unigram features and 40,000 new instances, achieved an F1 score of 69%, which outperforms the initial model’s F1 score of 54% in its best configuration (a <a class="keyword" href="https://en.wikipedia.org/wiki/logistic_regression" title="logistic regression">logistic regression</a> model employing unigram features). <mark class="fact">This noteworthy improvement of 15% in F1 score reaffirms the effectiveness of our approach</mark>, <mark class="fact">a result consistently observed across both traditional machine learning</mark> and <a class="keyword" href="https://en.wikipedia.org/wiki/Deep_learning" title="deep learning">deep learning</a> model experiments

##  Builds on previous research
- They found that commonly used negative word lists developed for other disciplines, such as the Harvard Dictionary, often misclassify common words in financial contexts. A more ==recent study by [^Gupta_2020_a]) utilized a sentiment analysis experiment combination of machine learning techniques and Term Frequency-Inverse Document Frequency (TF-IDF) to predict stock market price differences happening periodically==.

## Differs from previous work
- However, sentiment analysis of tweets can provide additional information about the market directions that can help investors make more concrete decisions ([^Tumasjan_et+al_2010_a]). ==Furthermore, the major obstacle to working on social media datasets in sentiment analysis is the need for available labeled instances to build supervised learning models== ([^Aroyehun_2018_a]).

## Contributions
- <mark class="fact">Sentiment analysis stands as a pivotal research endeavor within the machine learning and data science fields</mark>, where it finds widespread applications across various domains, encompassing individual opinions on products or services to collective expressions in social media posts. <mark class="fact">The conclusive findings presented in Sect</mark>. 5 <mark class="fact">unequivocally validate our hypothesis that the incremental inclusion of new samples significantly enhances the performance of the models</mark>. Specifically, the optimal machine learning model, constructed using the random forest algorithm with unigram features and 40,000 new instances, achieved an F1 score of 69%, which outperforms the initial model’s F1 score of 54% in its best configuration (a logistic regression model employing unigram features). <mark class="fact">This noteworthy improvement of 15% in F1 score reaffirms the effectiveness of our approach</mark>, <mark class="fact">a result consistently observed across both traditional machine learning</mark> and deep learning model experiments.


## References
[^Akbiyik_2023_a]: Akbiyik, M. E., Erkul, M., Kämpf, K., Vasiliauskaite, V., &amp;amp; Antulov-Fantulin, N. (2023). Ask&amp;quot; who&amp;quot;, not&amp;quot; what&amp;quot;: Bitcoin volatility forecasting with twitter data. In: Proceedings of the sixteenth ACM international conference on web search and data mining, pp. 688–696.  [OA](https://scholar.google.co.uk/scholar?q=Akbiyik%20M%20E%20Erkul%20M%20K%C3%A4mpf%20K%20Vasiliauskaite%20V%20amp%20AntulovFantulin%20N%202023%20Askquot%20whoquot%20notquot%20whatquot%20Bitcoin%20volatility%20forecasting%20with%20twitter%20data%20In%20Proceedings%20of%20the%20sixteenth%20ACM%20international%20conference%20on%20web%20search%20and%20data%20mining%20pp%20688696) [GScholar](https://scholar.google.co.uk/scholar?q=Akbiyik%20M%20E%20Erkul%20M%20K%C3%A4mpf%20K%20Vasiliauskaite%20V%20amp%20AntulovFantulin%20N%202023%20Askquot%20whoquot%20notquot%20whatquot%20Bitcoin%20volatility%20forecasting%20with%20twitter%20data%20In%20Proceedings%20of%20the%20sixteenth%20ACM%20international%20conference%20on%20web%20search%20and%20data%20mining%20pp%20688696) 

[^Al-Shargabi_2011_a]: Al-Shargabi, B., Al-Romimah, W., &amp;amp; Olayah, F. (2011). A comparative study for arabic text classification algorithms based on stop words elimination. In: Proceedings of the 2011 international conference on intelligent semantic web-services and applications, pp. 1–5.  [OA](https://scholar.google.co.uk/scholar?q=AlShargabi%20B%20AlRomimah%20W%20amp%20Olayah%20F%202011%20A%20comparative%20study%20for%20arabic%20text%20classification%20algorithms%20based%20on%20stop%20words%20elimination%20In%20Proceedings%20of%20the%202011%20international%20conference%20on%20intelligent%20semantic%20webservices%20and%20applications%20pp%2015) [GScholar](https://scholar.google.co.uk/scholar?q=AlShargabi%20B%20AlRomimah%20W%20amp%20Olayah%20F%202011%20A%20comparative%20study%20for%20arabic%20text%20classification%20algorithms%20based%20on%20stop%20words%20elimination%20In%20Proceedings%20of%20the%202011%20international%20conference%20on%20intelligent%20semantic%20webservices%20and%20applications%20pp%2015) 

[^Antweiler_2004_a]: Antweiler, W., &amp;amp; Frank, M. Z. (2004). Is all that talk just noise? The information content of internet stock message boards. The Journal of finance,59(3), 1259–1294.  [OA](https://engine.scholarcy.com/oa_version?query=Antweiler%20W%20amp%20Frank%20M%20Z%202004%20Is%20all%20that%20talk%20just%20noise%20The%20information%20content%20of%20internet%20stock%20message%20boards%20The%20Journal%20of%20finance593%2012591294&author=Antweiler&title=Is%20all%20that%20talk%20just%20noise%3F%20The%20information%20content%20of%20internet%20stock%20message%20boards&year=2004) [GScholar](https://scholar.google.co.uk/scholar?q=Antweiler%20W%20amp%20Frank%20M%20Z%202004%20Is%20all%20that%20talk%20just%20noise%20The%20information%20content%20of%20internet%20stock%20message%20boards%20The%20Journal%20of%20finance593%2012591294) [Scite](/scite_tallies?query=author%3AAntweiler%2Ctitle%3AIs%20all%20that%20talk%20just%20noise%3F%20The%20information%20content%20of%20internet%20stock%20message%20boards%2Cyear%3A2004)

[^Aroyehun_2018_a]: Aroyehun, S. T., Gelbukh, A. (2018). Aggression detection in social media: Using deep neural networks, data augmentation, and pseudo labeling. In: Proceedings of the first workshop on trolling, aggression and cyberbullying (TRAC-2018), pp. 90–97.  [OA](https://scholar.google.co.uk/scholar?q=Aroyehun%2C%20S.T.%20Gelbukh%2C%20A.%20Aggression%20detection%20in%20social%20media%3A%20Using%20deep%20neural%20networks%2C%20data%20augmentation%2C%20and%20pseudo%20labeling%202018) [GScholar](https://scholar.google.co.uk/scholar?q=Aroyehun%2C%20S.T.%20Gelbukh%2C%20A.%20Aggression%20detection%20in%20social%20media%3A%20Using%20deep%20neural%20networks%2C%20data%20augmentation%2C%20and%20pseudo%20labeling%202018) 

[^Bacco_2024_a]: Bacco, L., Petrosino, L., Arganese, D., Vollero, L., Papi, M., &amp;amp; Merone, M. (2024). Investigating stock prediction using lstm networks and sentiment analysis of tweets under high uncertainty: A case study of north american and european banks. IEEE Access.  [OA](https://engine.scholarcy.com/oa_version?query=Bacco%20L%20Petrosino%20L%20Arganese%20D%20Vollero%20L%20Papi%20M%20amp%20Merone%20M%202024%20Investigating%20stock%20prediction%20using%20lstm%20networks%20and%20sentiment%20analysis%20of%20tweets%20under%20high%20uncertainty%20A%20case%20study%20of%20north%20american%20and%20european%20banks%20IEEE%20Access&author=Bacco&title=Investigating%20stock%20prediction%20using%20lstm%20networks%20and%20sentiment%20analysis%20of%20tweets%20under%20high%20uncertainty%3A%20A%20case%20study%20of%20north%20american%20and%20european%20banks&year=2024) [GScholar](https://scholar.google.co.uk/scholar?q=Bacco%20L%20Petrosino%20L%20Arganese%20D%20Vollero%20L%20Papi%20M%20amp%20Merone%20M%202024%20Investigating%20stock%20prediction%20using%20lstm%20networks%20and%20sentiment%20analysis%20of%20tweets%20under%20high%20uncertainty%20A%20case%20study%20of%20north%20american%20and%20european%20banks%20IEEE%20Access) [Scite](/scite_tallies?query=author%3ABacco%2Ctitle%3AInvestigating%20stock%20prediction%20using%20lstm%20networks%20and%20sentiment%20analysis%20of%20tweets%20under%20high%20uncertainty%3A%20A%20case%20study%20of%20north%20american%20and%20european%20banks%2Cyear%3A2024)

[^Bakal_2021_a]: Bakal, G., &amp;amp; Abar, O. (2021). On comparative classification of relevant covid-19 tweets. In: 2021 6th international conference on computer science and engineering (UBMK), IEEE, pp. 287–291.  [OA](https://scholar.google.co.uk/scholar?q=Bakal%20G%20amp%20Abar%20O%202021%20On%20comparative%20classification%20of%20relevant%20covid19%20tweets%20In%202021%206th%20international%20conference%20on%20computer%20science%20and%20engineering%20UBMK%20IEEE%20pp%20287291) [GScholar](https://scholar.google.co.uk/scholar?q=Bakal%20G%20amp%20Abar%20O%202021%20On%20comparative%20classification%20of%20relevant%20covid19%20tweets%20In%202021%206th%20international%20conference%20on%20computer%20science%20and%20engineering%20UBMK%20IEEE%20pp%20287291) 

[^Bakal_2015_a]: Bakal, G., &amp;amp; Kavuluru, R. (2015). Predicting treatment relations with semantic patterns over biomedical knowledge graphs. In: International conference on mining intelligence and knowledge exploration, Springer, pp. 586–596.  [OA](https://scholar.google.co.uk/scholar?q=Bakal%20G%20amp%20Kavuluru%20R%202015%20Predicting%20treatment%20relations%20with%20semantic%20patterns%20over%20biomedical%20knowledge%20graphs%20In%20International%20conference%20on%20mining%20intelligence%20and%20knowledge%20exploration%20Springer%20pp%20586596) [GScholar](https://scholar.google.co.uk/scholar?q=Bakal%20G%20amp%20Kavuluru%20R%202015%20Predicting%20treatment%20relations%20with%20semantic%20patterns%20over%20biomedical%20knowledge%20graphs%20In%20International%20conference%20on%20mining%20intelligence%20and%20knowledge%20exploration%20Springer%20pp%20586596) 

[^Bollen_2011_a]: Bollen, J., Mao, H., &amp;amp; Zeng, X. (2011). Twitter mood predicts the stock market. Journal of computational science,2(1), 1–8.  [OA](https://engine.scholarcy.com/oa_version?query=Bollen%20J%20Mao%20H%20amp%20Zeng%20X%202011%20Twitter%20mood%20predicts%20the%20stock%20market%20Journal%20of%20computational%20science21%2018&author=Bollen&title=Twitter%20mood%20predicts%20the%20stock%20market&year=2011) [GScholar](https://scholar.google.co.uk/scholar?q=Bollen%20J%20Mao%20H%20amp%20Zeng%20X%202011%20Twitter%20mood%20predicts%20the%20stock%20market%20Journal%20of%20computational%20science21%2018) [Scite](/scite_tallies?query=author%3ABollen%2Ctitle%3ATwitter%20mood%20predicts%20the%20stock%20market%2Cyear%3A2011)

[^Bozdag_2024_a]: Bozdag, M., Sevim, N., &amp;amp; Koç, A. (2024). Measuring and mitigating gender bias in legal contextualized language models. ACM Transactions on Knowledge Discovery from Data. https://doi.org/10.1145/3628602  [OA](https://doi.org/10.1145/3628602)  [Scite](/scite_tallies?query=https://doi.org/10.1145/3628602)

[^Breiman_2001_a]: Breiman, L. (2001). Random forests. Machine Learning,45, 5–32.  [OA](https://scholar.google.co.uk/scholar?q=Breiman%2C%20L.%20Random%20forests%202001) [GScholar](https://scholar.google.co.uk/scholar?q=Breiman%2C%20L.%20Random%20forests%202001) 

[^Cavnar_1994_a]: Cavnar, W. B., Trenkle, J. M., et al. (1994). N-gram-based text categorization. In: Proceedings of SDAIR-94, 3rd annual symposium on document analysis and information retrieval, Las Vegas, NV, pp. 161–175.  [OA](https://scholar.google.co.uk/scholar?q=Cavnar%2C%20W.B.%20Trenkle%2C%20J.M.%20N-gram-based%20text%20categorization%201994) [GScholar](https://scholar.google.co.uk/scholar?q=Cavnar%2C%20W.B.%20Trenkle%2C%20J.M.%20N-gram-based%20text%20categorization%201994) 

[^Cezanne_2020_a]: Cezanne, C. (2020). Cnn for text classification. https://cezannec.github.io/CNN_Text_Classification, accessed:2024-09-12.  [OA](https://cezannec.github.io/CNN_Text_Classification)  

[^Chen_2016_a]: Chen, T., &amp;amp; Guestrin, C. (2016). Xgboost: A scalable tree boosting system. In: Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining, pp. 785–794.  [OA](https://scholar.google.co.uk/scholar?q=Chen%20T%20amp%20Guestrin%20C%202016%20Xgboost%20A%20scalable%20tree%20boosting%20system%20In%20Proceedings%20of%20the%2022nd%20acm%20sigkdd%20international%20conference%20on%20knowledge%20discovery%20and%20data%20mining%20pp%20785794) [GScholar](https://scholar.google.co.uk/scholar?q=Chen%20T%20amp%20Guestrin%20C%202016%20Xgboost%20A%20scalable%20tree%20boosting%20system%20In%20Proceedings%20of%20the%2022nd%20acm%20sigkdd%20international%20conference%20on%20knowledge%20discovery%20and%20data%20mining%20pp%20785794) 

[^Day_2016_a]: Day, M. Y., &amp;amp; Lee, C. C. (2016). Deep learning for financial sentiment analysis on finance news providers. In: 2016 IEEE/ACM international conference on advances in social networks analysis and mining (ASONAM), IEEE, pp. 1127–1134.  [OA](https://scholar.google.co.uk/scholar?q=Day%20M%20Y%20amp%20Lee%20C%20C%202016%20Deep%20learning%20for%20financial%20sentiment%20analysis%20on%20finance%20news%20providers%20In%202016%20IEEEACM%20international%20conference%20on%20advances%20in%20social%20networks%20analysis%20and%20mining%20ASONAM%20IEEE%20pp%2011271134) [GScholar](https://scholar.google.co.uk/scholar?q=Day%20M%20Y%20amp%20Lee%20C%20C%202016%20Deep%20learning%20for%20financial%20sentiment%20analysis%20on%20finance%20news%20providers%20In%202016%20IEEEACM%20international%20conference%20on%20advances%20in%20social%20networks%20analysis%20and%20mining%20ASONAM%20IEEE%20pp%2011271134) 

[^Erkantarci_2023_a]: Erkantarci, B., &amp;amp; Bakal, G. (2023). An empirical study of sentiment analysis utilizing machine learning and deep learning algorithms. Journal of Computational Social Science, pp. 1–17.  [OA](https://engine.scholarcy.com/oa_version?query=Erkantarci%20B%20amp%20Bakal%20G%202023%20An%20empirical%20study%20of%20sentiment%20analysis%20utilizing%20machine%20learning%20and%20deep%20learning%20algorithms%20Journal%20of%20Computational%20Social%20Science%20pp%20117&author=Erkantarci&title=An%20empirical%20study%20of%20sentiment%20analysis%20utilizing%20machine%20learning%20and%20deep%20learning%20algorithms&year=2023) [GScholar](https://scholar.google.co.uk/scholar?q=Erkantarci%20B%20amp%20Bakal%20G%202023%20An%20empirical%20study%20of%20sentiment%20analysis%20utilizing%20machine%20learning%20and%20deep%20learning%20algorithms%20Journal%20of%20Computational%20Social%20Science%20pp%20117) [Scite](/scite_tallies?query=author%3AErkantarci%2Ctitle%3AAn%20empirical%20study%20of%20sentiment%20analysis%20utilizing%20machine%20learning%20and%20deep%20learning%20algorithms%2Cyear%3A2023)

[^Gandhudi_2024_a]: Gandhudi, M., Alphonse, P. J. A., Fiore, U., &amp;amp; Gangadharan, G. R. (2024). Explainable hybrid quantum neural networks for analyzing the influence of tweets on stock price prediction. Computers and Electrical Engineering,118(109), 302.  [OA](https://scholar.google.co.uk/scholar?q=Gandhudi%20M%20Alphonse%20P%20J%20A%20Fiore%20U%20amp%20Gangadharan%20G%20R%202024%20Explainable%20hybrid%20quantum%20neural%20networks%20for%20analyzing%20the%20influence%20of%20tweets%20on%20stock%20price%20prediction%20Computers%20and%20Electrical%20Engineering118109%20302) [GScholar](https://scholar.google.co.uk/scholar?q=Gandhudi%20M%20Alphonse%20P%20J%20A%20Fiore%20U%20amp%20Gangadharan%20G%20R%202024%20Explainable%20hybrid%20quantum%20neural%20networks%20for%20analyzing%20the%20influence%20of%20tweets%20on%20stock%20price%20prediction%20Computers%20and%20Electrical%20Engineering118109%20302) 

[^Gu_2018_a]: Gu, J., Wang, Z., Kuen, J., Ma, L., Shahroudy, A., Shuai, B., Liu, T., Wang, X., Wang, G., Cai, J., &amp;amp; Chen, T. (2018). Recent advances in convolutional neural networks. Pattern Recognition,77, 354–377.  [OA](https://scholar.google.co.uk/scholar?q=Gu%20J%20Wang%20Z%20Kuen%20J%20Ma%20L%20Shahroudy%20A%20Shuai%20B%20Liu%20T%20Wang%20X%20Wang%20G%20Cai%20J%20amp%20Chen%20T%202018%20Recent%20advances%20in%20convolutional%20neural%20networks%20Pattern%20Recognition77%20354377) [GScholar](https://scholar.google.co.uk/scholar?q=Gu%20J%20Wang%20Z%20Kuen%20J%20Ma%20L%20Shahroudy%20A%20Shuai%20B%20Liu%20T%20Wang%20X%20Wang%20G%20Cai%20J%20amp%20Chen%20T%202018%20Recent%20advances%20in%20convolutional%20neural%20networks%20Pattern%20Recognition77%20354377) 

[^Gupta_2020_a]: Gupta, R., &amp;amp; Chen, M. (2020). Sentiment analysis for stock price prediction. In: 2020 IEEE conference on multimedia information processing and retrieval (MIPR), IEEE, pp. 213–218.  [OA](https://scholar.google.co.uk/scholar?q=Gupta%20R%20amp%20Chen%20M%202020%20Sentiment%20analysis%20for%20stock%20price%20prediction%20In%202020%20IEEE%20conference%20on%20multimedia%20information%20processing%20and%20retrieval%20MIPR%20IEEE%20pp%20213218) [GScholar](https://scholar.google.co.uk/scholar?q=Gupta%20R%20amp%20Chen%20M%202020%20Sentiment%20analysis%20for%20stock%20price%20prediction%20In%202020%20IEEE%20conference%20on%20multimedia%20information%20processing%20and%20retrieval%20MIPR%20IEEE%20pp%20213218) 

[^Joachims_1996_a]: Joachims, T. (1996). A probabilistic analysis of the rocchio algorithm with tfidf for text categorization. Tech. rep., Carnegie-mellon univ pittsburgh pa dept of computer science.  [OA](https://engine.scholarcy.com/oa_version?query=Joachims%2C%20T.%20A%20probabilistic%20analysis%20of%20the%20rocchio%20algorithm%20with%20tfidf%20for%20text%20categorization%201996&author=Joachims&title=A%20probabilistic%20analysis%20of%20the%20rocchio%20algorithm%20with%20tfidf%20for%20text%20categorization&year=1996) [GScholar](https://scholar.google.co.uk/scholar?q=Joachims%2C%20T.%20A%20probabilistic%20analysis%20of%20the%20rocchio%20algorithm%20with%20tfidf%20for%20text%20categorization%201996) [Scite](/scite_tallies?query=author%3AJoachims%2Ctitle%3AA%20probabilistic%20analysis%20of%20the%20rocchio%20algorithm%20with%20tfidf%20for%20text%20categorization%2Cyear%3A1996)

[^Josephine_2021_a]: Josephine, J., Ulaganathan, M., Shenbagavalli, A., Venkatraman, B., &amp;amp; Menaka, M. (2021). Statistical analysis on breast thermograms using logistic regression for image classification. In: 2021 IEEE Bombay section signature conference (IBSSC), IEEE, pp. 1–6.  [OA](https://scholar.google.co.uk/scholar?q=Josephine%20J%20Ulaganathan%20M%20Shenbagavalli%20A%20Venkatraman%20B%20amp%20Menaka%20M%202021%20Statistical%20analysis%20on%20breast%20thermograms%20using%20logistic%20regression%20for%20image%20classification%20In%202021%20IEEE%20Bombay%20section%20signature%20conference%20IBSSC%20IEEE%20pp%2016) [GScholar](https://scholar.google.co.uk/scholar?q=Josephine%20J%20Ulaganathan%20M%20Shenbagavalli%20A%20Venkatraman%20B%20amp%20Menaka%20M%202021%20Statistical%20analysis%20on%20breast%20thermograms%20using%20logistic%20regression%20for%20image%20classification%20In%202021%20IEEE%20Bombay%20section%20signature%20conference%20IBSSC%20IEEE%20pp%2016) 

[^Khafaga_2023_a]: Khafaga, D. S., Auvdaiappan, M., Deepa, K., Abouhawwash, M., &amp;amp; Karim, F. K. (2023). Deep learning for depression detection using twitter data. Intelligent Automation &amp;amp; Soft Computing,36(2), 1301–1313.  [OA](https://engine.scholarcy.com/oa_version?query=Khafaga%20D%20S%20Auvdaiappan%20M%20Deepa%20K%20Abouhawwash%20M%20amp%20Karim%20F%20K%202023%20Deep%20learning%20for%20depression%20detection%20using%20twitter%20data%20Intelligent%20Automation%20amp%20Soft%20Computing362%2013011313&author=Khafaga&title=Deep%20learning%20for%20depression%20detection%20using%20twitter%20data&year=2023) [GScholar](https://scholar.google.co.uk/scholar?q=Khafaga%20D%20S%20Auvdaiappan%20M%20Deepa%20K%20Abouhawwash%20M%20amp%20Karim%20F%20K%202023%20Deep%20learning%20for%20depression%20detection%20using%20twitter%20data%20Intelligent%20Automation%20amp%20Soft%20Computing362%2013011313) [Scite](/scite_tallies?query=author%3AKhafaga%2Ctitle%3ADeep%20learning%20for%20depression%20detection%20using%20twitter%20data%2Cyear%3A2023)

[^Kumar_2014_a]: Kumar, S., Morstatter, F., &amp;amp; Liu, H. (2014). Twitter data analytics. Springer.  [OA](https://scholar.google.co.uk/scholar?q=Kumar%20S%20Morstatter%20F%20amp%20Liu%20H%202014%20Twitter%20data%20analytics%20Springer) [GScholar](https://scholar.google.co.uk/scholar?q=Kumar%20S%20Morstatter%20F%20amp%20Liu%20H%202014%20Twitter%20data%20analytics%20Springer) 

[^Lecun_2015_a]: LeCun, Y., Bengio, Y., &amp;amp; Hinton, G. (2015). Deep learning. Nature,521(7553), 436–444.  [OA](https://engine.scholarcy.com/oa_version?query=LeCun%20Y%20Bengio%20Y%20amp%20Hinton%20G%202015%20Deep%20learning%20Nature5217553%20436444&author=Lecun&title=&year=2015) [GScholar](https://scholar.google.co.uk/scholar?q=LeCun%20Y%20Bengio%20Y%20amp%20Hinton%20G%202015%20Deep%20learning%20Nature5217553%20436444) [Scite](/scite_tallies?query=LeCun%2C%20Y.%2C%20Bengio%2C%20Y.%2C%20%26amp%3B%20Hinton%2C%20G.%20%282015%29.%20Deep%20learning.%20Nature%2C521%287553%29%2C%20436%E2%80%93444.)

[^Liu_2012_a]: Liu, B. (2012). Sentiment analysis and opinion mining. Synthesis Lectures on Human Language Technologies,5(1), 1–167.  [OA](https://engine.scholarcy.com/oa_version?query=Liu%2C%20B.%20Sentiment%20analysis%20and%20opinion%20mining%202012&author=Liu&title=Sentiment%20analysis%20and%20opinion%20mining&year=2012) [GScholar](https://scholar.google.co.uk/scholar?q=Liu%2C%20B.%20Sentiment%20analysis%20and%20opinion%20mining%202012) [Scite](/scite_tallies?query=author%3ALiu%2Ctitle%3ASentiment%20analysis%20and%20opinion%20mining%2Cyear%3A2012)

[^Loper_2002_a]: Loper, E., &amp;amp; Bird, S. (2002). Nltk: The natural language toolkit. arXiv preprint cs/0205028.  [OA](https://scholar.google.co.uk/scholar?q=Loper%20E%20amp%20Bird%20S%202002%20Nltk%20The%20natural%20language%20toolkit%20arXiv%20preprint%20cs0205028) [GScholar](https://scholar.google.co.uk/scholar?q=Loper%20E%20amp%20Bird%20S%202002%20Nltk%20The%20natural%20language%20toolkit%20arXiv%20preprint%20cs0205028) 

[^Loughran_2011_a]: Loughran, T., &amp;amp; McDonald, B. (2011). When is a liability not a liability? Textual analysis, dictionaries, and 10-ks. The Journal of Finance,66(1), 35–65.  [OA](https://engine.scholarcy.com/oa_version?query=Loughran%20T%20amp%20McDonald%20B%202011%20When%20is%20a%20liability%20not%20a%20liability%20Textual%20analysis%20dictionaries%20and%2010ks%20The%20Journal%20of%20Finance661%203565&author=Loughran&title=When%20is%20a%20liability%20not%20a%20liability%3F%20Textual%20analysis%2C%20dictionaries%2C%20and%2010-ks&year=2011) [GScholar](https://scholar.google.co.uk/scholar?q=Loughran%20T%20amp%20McDonald%20B%202011%20When%20is%20a%20liability%20not%20a%20liability%20Textual%20analysis%20dictionaries%20and%2010ks%20The%20Journal%20of%20Finance661%203565) [Scite](/scite_tallies?query=author%3ALoughran%2Ctitle%3AWhen%20is%20a%20liability%20not%20a%20liability%3F%20Textual%20analysis%2C%20dictionaries%2C%20and%2010-ks%2Cyear%3A2011)

[^Malo_2014_a]: Malo, P., Sinha, A., Korhonen, P., Wallenius, J., &amp;amp; Takala, P. (2014). Good debt or bad debt: Detecting semantic orientations in economic texts. Journal of the Association for Information Science and Technology,65(4), 782–796.  [OA](https://engine.scholarcy.com/oa_version?query=Malo%20P%20Sinha%20A%20Korhonen%20P%20Wallenius%20J%20amp%20Takala%20P%202014%20Good%20debt%20or%20bad%20debt%20Detecting%20semantic%20orientations%20in%20economic%20texts%20Journal%20of%20the%20Association%20for%20Information%20Science%20and%20Technology654%20782796&author=Malo&title=Good%20debt%20or%20bad%20debt%3A%20Detecting%20semantic%20orientations%20in%20economic%20texts&year=2014) [GScholar](https://scholar.google.co.uk/scholar?q=Malo%20P%20Sinha%20A%20Korhonen%20P%20Wallenius%20J%20amp%20Takala%20P%202014%20Good%20debt%20or%20bad%20debt%20Detecting%20semantic%20orientations%20in%20economic%20texts%20Journal%20of%20the%20Association%20for%20Information%20Science%20and%20Technology654%20782796) [Scite](/scite_tallies?query=author%3AMalo%2Ctitle%3AGood%20debt%20or%20bad%20debt%3A%20Detecting%20semantic%20orientations%20in%20economic%20texts%2Cyear%3A2014)

[^Medhat_2014_a]: Medhat, W., Hassan, A., &amp;amp; Korashy, H. (2014). Sentiment analysis algorithms and applications: A survey. Ain Shams Engineering Journal,5(4), 1093–1113.  [OA](https://engine.scholarcy.com/oa_version?query=Medhat%20W%20Hassan%20A%20amp%20Korashy%20H%202014%20Sentiment%20analysis%20algorithms%20and%20applications%20A%20survey%20Ain%20Shams%20Engineering%20Journal54%2010931113&author=Medhat&title=Sentiment%20analysis%20algorithms%20and%20applications%3A%20A%20survey&year=2014) [GScholar](https://scholar.google.co.uk/scholar?q=Medhat%20W%20Hassan%20A%20amp%20Korashy%20H%202014%20Sentiment%20analysis%20algorithms%20and%20applications%20A%20survey%20Ain%20Shams%20Engineering%20Journal54%2010931113) [Scite](/scite_tallies?query=author%3AMedhat%2Ctitle%3ASentiment%20analysis%20algorithms%20and%20applications%3A%20A%20survey%2Cyear%3A2014)

[^Melli_XXXX_a]: Melli, G. (n.d.) (2024). Long short-term memory (lstm) unit. https://www.gabormelli.com/RKB/Long_Short-Term_Memory_%28LSTM%29_Unit accessed:2024-09-12.  [OA](https://www.gabormelli.com/RKB/Long_Short-Term_Memory_%28LSTM%29_Unit)  

[^Meng_2023_a]: Meng, M., Zhang, Y., Ma, Y., Gao, Y., &amp;amp; Kong, W. (2023). Eeg-based emotion recognition with cascaded convolutional recurrent neural networks. Pattern Analysis and Applications,26(2), 783–795.  [OA](https://engine.scholarcy.com/oa_version?query=Meng%20M%20Zhang%20Y%20Ma%20Y%20Gao%20Y%20amp%20Kong%20W%202023%20Eegbased%20emotion%20recognition%20with%20cascaded%20convolutional%20recurrent%20neural%20networks%20Pattern%20Analysis%20and%20Applications262%20783795&author=Meng&title=Eeg-based%20emotion%20recognition%20with%20cascaded%20convolutional%20recurrent%20neural%20networks&year=2023) [GScholar](https://scholar.google.co.uk/scholar?q=Meng%20M%20Zhang%20Y%20Ma%20Y%20Gao%20Y%20amp%20Kong%20W%202023%20Eegbased%20emotion%20recognition%20with%20cascaded%20convolutional%20recurrent%20neural%20networks%20Pattern%20Analysis%20and%20Applications262%20783795) [Scite](/scite_tallies?query=author%3AMeng%2Ctitle%3AEeg-based%20emotion%20recognition%20with%20cascaded%20convolutional%20recurrent%20neural%20networks%2Cyear%3A2023)

[^Pedregosa_2011_a]: Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., &amp;amp; Vanderplas, J. (2011). Scikit-learn: Machine learning in python. The Journal of Machine Learning Research,12, 2825–2830.  [OA](https://engine.scholarcy.com/oa_version?query=Pedregosa%20F%20Varoquaux%20G%20Gramfort%20A%20Michel%20V%20Thirion%20B%20Grisel%20O%20Blondel%20M%20Prettenhofer%20P%20Weiss%20R%20Dubourg%20V%20amp%20Vanderplas%20J%202011%20Scikitlearn%20Machine%20learning%20in%20python%20The%20Journal%20of%20Machine%20Learning%20Research12%2028252830&author=Pedregosa&title=Scikit-learn%3A%20Machine%20learning%20in%20python&year=2011) [GScholar](https://scholar.google.co.uk/scholar?q=Pedregosa%20F%20Varoquaux%20G%20Gramfort%20A%20Michel%20V%20Thirion%20B%20Grisel%20O%20Blondel%20M%20Prettenhofer%20P%20Weiss%20R%20Dubourg%20V%20amp%20Vanderplas%20J%202011%20Scikitlearn%20Machine%20learning%20in%20python%20The%20Journal%20of%20Machine%20Learning%20Research12%2028252830) [Scite](/scite_tallies?query=author%3APedregosa%2Ctitle%3AScikit-learn%3A%20Machine%20learning%20in%20python%2Cyear%3A2011)

[^Prosusai_2020_a]: ProsusAI (2020). finbert: Financial sentiment analysis with bert. https://github.com/ProsusAI/finBERT.  [OA](https://github.com/ProsusAI/finBERT)  

[^Rodriguez-Galiano_2012_a]: Rodriguez-Galiano, V. F., Ghimire, B., Rogan, J., Chica-Olmo, M., &amp;amp; Rigol-Sanchez, J. P. (2012). An assessment of the effectiveness of a random forest classifier for land-cover classification. ISPRS Journal of Photogrammetry and Remote Sensing,67, 93–104.  [OA](https://engine.scholarcy.com/oa_version?query=RodriguezGaliano%20V%20F%20Ghimire%20B%20Rogan%20J%20ChicaOlmo%20M%20amp%20RigolSanchez%20J%20P%202012%20An%20assessment%20of%20the%20effectiveness%20of%20a%20random%20forest%20classifier%20for%20landcover%20classification%20ISPRS%20Journal%20of%20Photogrammetry%20and%20Remote%20Sensing67%2093104&author=Rodriguez-Galiano&title=An%20assessment%20of%20the%20effectiveness%20of%20a%20random%20forest%20classifier%20for%20land-cover%20classification&year=2012) [GScholar](https://scholar.google.co.uk/scholar?q=RodriguezGaliano%20V%20F%20Ghimire%20B%20Rogan%20J%20ChicaOlmo%20M%20amp%20RigolSanchez%20J%20P%202012%20An%20assessment%20of%20the%20effectiveness%20of%20a%20random%20forest%20classifier%20for%20landcover%20classification%20ISPRS%20Journal%20of%20Photogrammetry%20and%20Remote%20Sensing67%2093104) [Scite](/scite_tallies?query=author%3ARodriguez-Galiano%2Ctitle%3AAn%20assessment%20of%20the%20effectiveness%20of%20a%20random%20forest%20classifier%20for%20land-cover%20classification%2Cyear%3A2012)

[^Roesslein_2020_a]: Roesslein, J. (2020). Tweepy: Twitter for python!.  [OA](https://scholar.google.co.uk/scholar?q=Roesslein%2C%20J.%20Tweepy%3A%20Twitter%20for%20python%21%202020) [GScholar](https://scholar.google.co.uk/scholar?q=Roesslein%2C%20J.%20Tweepy%3A%20Twitter%20for%20python%21%202020) 

[^Shah_2020_a]: Shah, K., Patel, H., Sanghvi, D., &amp;amp; Shah, M. (2020). A comparative analysis of logistic regression, random forest and knn models for the text classification. Augmented Human Research,5, 1–16.  [OA](https://engine.scholarcy.com/oa_version?query=Shah%20K%20Patel%20H%20Sanghvi%20D%20amp%20Shah%20M%202020%20A%20comparative%20analysis%20of%20logistic%20regression%20random%20forest%20and%20knn%20models%20for%20the%20text%20classification%20Augmented%20Human%20Research5%20116&author=Shah&title=A%20comparative%20analysis%20of%20logistic%20regression%2C%20random%20forest%20and%20knn%20models%20for%20the%20text%20classification&year=2020) [GScholar](https://scholar.google.co.uk/scholar?q=Shah%20K%20Patel%20H%20Sanghvi%20D%20amp%20Shah%20M%202020%20A%20comparative%20analysis%20of%20logistic%20regression%20random%20forest%20and%20knn%20models%20for%20the%20text%20classification%20Augmented%20Human%20Research5%20116) [Scite](/scite_tallies?query=author%3AShah%2Ctitle%3AA%20comparative%20analysis%20of%20logistic%20regression%2C%20random%20forest%20and%20knn%20models%20for%20the%20text%20classification%2Cyear%3A2020)

[^Sherstinsky_2020_a]: Sherstinsky, A. (2020). Fundamentals of recurrent neural network (rnn) and long short-term memory (lstm) network. Physica D: Nonlinear Phenomena,404(132), 306.  [OA](https://scholar.google.co.uk/scholar?q=Sherstinsky%2C%20A.%20Fundamentals%20of%20recurrent%20neural%20network%20%28rnn%29%20and%20long%20short-term%20memory%20%28lstm%29%20network%202020) [GScholar](https://scholar.google.co.uk/scholar?q=Sherstinsky%2C%20A.%20Fundamentals%20of%20recurrent%20neural%20network%20%28rnn%29%20and%20long%20short-term%20memory%20%28lstm%29%20network%202020) 

[^Silva_2003_a]: Silva, C., &amp;amp; Ribeiro, B. (2003). The importance of stop word removal on recall values in text categorization. In: Proceedings of the international joint conference on neural networks, IEEE, pp. 1661–1666.  [OA](https://scholar.google.co.uk/scholar?q=Silva%20C%20amp%20Ribeiro%20B%202003%20The%20importance%20of%20stop%20word%20removal%20on%20recall%20values%20in%20text%20categorization%20In%20Proceedings%20of%20the%20international%20joint%20conference%20on%20neural%20networks%20IEEE%20pp%2016611666) [GScholar](https://scholar.google.co.uk/scholar?q=Silva%20C%20amp%20Ribeiro%20B%202003%20The%20importance%20of%20stop%20word%20removal%20on%20recall%20values%20in%20text%20categorization%20In%20Proceedings%20of%20the%20international%20joint%20conference%20on%20neural%20networks%20IEEE%20pp%2016611666) 

[^Sohangir_2018_a]: Sohangir, S., Wang, D., Pomeranets, A., &amp;amp; Khoshgoftaar, T. M. (2018). Big data: Deep learning for financial sentiment analysis. Journal of Big Data,5(1), 1–25.  [OA](https://engine.scholarcy.com/oa_version?query=Sohangir%20S%20Wang%20D%20Pomeranets%20A%20amp%20Khoshgoftaar%20T%20M%202018%20Big%20data%20Deep%20learning%20for%20financial%20sentiment%20analysis%20Journal%20of%20Big%20Data51%20125&author=Sohangir&title=Big%20data%3A%20Deep%20learning%20for%20financial%20sentiment%20analysis&year=2018) [GScholar](https://scholar.google.co.uk/scholar?q=Sohangir%20S%20Wang%20D%20Pomeranets%20A%20amp%20Khoshgoftaar%20T%20M%202018%20Big%20data%20Deep%20learning%20for%20financial%20sentiment%20analysis%20Journal%20of%20Big%20Data51%20125) [Scite](/scite_tallies?query=author%3ASohangir%2Ctitle%3ABig%20data%3A%20Deep%20learning%20for%20financial%20sentiment%20analysis%2Cyear%3A2018)

[^Sun_2023_a]: Sun, L., Li, Q., Liu, L., &amp;amp; Su, Y. (2023). Unsupervised multimodal learning for image-text relation classification in tweets. Pattern Analysis and Applications,26(4), 1793–1804.  [OA](https://engine.scholarcy.com/oa_version?query=Sun%20L%20Li%20Q%20Liu%20L%20amp%20Su%20Y%202023%20Unsupervised%20multimodal%20learning%20for%20imagetext%20relation%20classification%20in%20tweets%20Pattern%20Analysis%20and%20Applications264%2017931804&author=Sun&title=Unsupervised%20multimodal%20learning%20for%20image-text%20relation%20classification%20in%20tweets&year=2023) [GScholar](https://scholar.google.co.uk/scholar?q=Sun%20L%20Li%20Q%20Liu%20L%20amp%20Su%20Y%202023%20Unsupervised%20multimodal%20learning%20for%20imagetext%20relation%20classification%20in%20tweets%20Pattern%20Analysis%20and%20Applications264%2017931804) [Scite](/scite_tallies?query=author%3ASun%2Ctitle%3AUnsupervised%20multimodal%20learning%20for%20image-text%20relation%20classification%20in%20tweets%2Cyear%3A2023)

[^Sungur_2025_a]: Sungur, K. S., &amp;amp; Bakal, G. (2025). Beyond visual cues: Emotion recognition in images with text-aware fusion. Displays, p. 102958.  [OA](https://engine.scholarcy.com/oa_version?query=Sungur%20K%20S%20amp%20Bakal%20G%202025%20Beyond%20visual%20cues%20Emotion%20recognition%20in%20images%20with%20textaware%20fusion%20Displays%20p%20102958&author=Sungur&title=Beyond%20visual%20cues%3A%20Emotion%20recognition%20in%20images%20with%20text-aware%20fusion&year=2025) [GScholar](https://scholar.google.co.uk/scholar?q=Sungur%20K%20S%20amp%20Bakal%20G%202025%20Beyond%20visual%20cues%20Emotion%20recognition%20in%20images%20with%20textaware%20fusion%20Displays%20p%20102958) [Scite](/scite_tallies?query=author%3ASungur%2Ctitle%3ABeyond%20visual%20cues%3A%20Emotion%20recognition%20in%20images%20with%20text-aware%20fusion%2Cyear%3A2025)

[^Taborda_2021_a]: Taborda, B., de Almeida, A., Dias, J. C., Batista, F., &amp;amp; Ribeiro, R. (2021). Stock market tweets data. IEEE Dataport.  [OA](https://scholar.google.co.uk/scholar?q=Taborda%20B%20de%20Almeida%20A%20Dias%20J%20C%20Batista%20F%20amp%20Ribeiro%20R%202021%20Stock%20market%20tweets%20data%20IEEE%20Dataport) [GScholar](https://scholar.google.co.uk/scholar?q=Taborda%20B%20de%20Almeida%20A%20Dias%20J%20C%20Batista%20F%20amp%20Ribeiro%20R%202021%20Stock%20market%20tweets%20data%20IEEE%20Dataport) 

[^Tumasjan_et+al_2010_a]: Tumasjan, A., Sprenger, T., Sandner, P., et al. (2010). Predicting elections with twitter: What 140 characters reveal about political sentiment. In: Proceedings of the international AAAI conference on web and social media, pp. 178–185.  [OA](https://scholar.google.co.uk/scholar?q=Tumasjan%2C%20A.%20Sprenger%2C%20T.%20Sandner%2C%20P.%20Predicting%20elections%20with%20twitter%3A%20What%20140%20characters%20reveal%20about%20political%20sentiment%202010) [GScholar](https://scholar.google.co.uk/scholar?q=Tumasjan%2C%20A.%20Sprenger%2C%20T.%20Sandner%2C%20P.%20Predicting%20elections%20with%20twitter%3A%20What%20140%20characters%20reveal%20about%20political%20sentiment%202010) 

[^Tun_2023_a]: Tun, Y. M., &amp;amp; Khaing, M. (2023). A large-scale sentiment analysis using political tweets. International Journal of Electrical &amp;amp; Computer Engineering (2088-8708) 13(6).  [OA](https://engine.scholarcy.com/oa_version?query=Tun%20Y%20M%20amp%20Khaing%20M%202023%20A%20largescale%20sentiment%20analysis%20using%20political%20tweets%20International%20Journal%20of%20Electrical%20amp%20Computer%20Engineering%2020888708%20136&author=Tun&title=A%20large-scale%20sentiment%20analysis%20using%20political%20tweets&year=2023) [GScholar](https://scholar.google.co.uk/scholar?q=Tun%20Y%20M%20amp%20Khaing%20M%202023%20A%20largescale%20sentiment%20analysis%20using%20political%20tweets%20International%20Journal%20of%20Electrical%20amp%20Computer%20Engineering%2020888708%20136) [Scite](/scite_tallies?query=author%3ATun%2Ctitle%3AA%20large-scale%20sentiment%20analysis%20using%20political%20tweets%2Cyear%3A2023)

[^Vaswani_2017_a]: Vaswani, A. (2017). Attention is all you need. Advances in Neural Information Processing Systems.  [OA](https://scholar.google.co.uk/scholar?q=Vaswani%2C%20A.%20Attention%20is%20all%20you%20need.%20Advances%20in%20Neural%20Information%20Processing%20Systems%202017) [GScholar](https://scholar.google.co.uk/scholar?q=Vaswani%2C%20A.%20Attention%20is%20all%20you%20need.%20Advances%20in%20Neural%20Information%20Processing%20Systems%202017) 

[^Yu_et+al_2019_a]: Yu, Y., Si, X., Hu, C., et al. (2019). A review of recurrent neural networks: Lstm cells and network architectures. Neural Computation,31(7), 1235–1270.  [OA](https://engine.scholarcy.com/oa_version?query=Yu%2C%20Y.%20Si%2C%20X.%20Hu%2C%20C.%20A%20review%20of%20recurrent%20neural%20networks%3A%20Lstm%20cells%20and%20network%20architectures%202019&author=Yu&title=A%20review%20of%20recurrent%20neural%20networks%3A%20Lstm%20cells%20and%20network%20architectures&year=2019) [GScholar](https://scholar.google.co.uk/scholar?q=Yu%2C%20Y.%20Si%2C%20X.%20Hu%2C%20C.%20A%20review%20of%20recurrent%20neural%20networks%3A%20Lstm%20cells%20and%20network%20architectures%202019) [Scite](/scite_tallies?query=author%3AYu%2Ctitle%3AA%20review%20of%20recurrent%20neural%20networks%3A%20Lstm%20cells%20and%20network%20architectures%2Cyear%3A2019)

