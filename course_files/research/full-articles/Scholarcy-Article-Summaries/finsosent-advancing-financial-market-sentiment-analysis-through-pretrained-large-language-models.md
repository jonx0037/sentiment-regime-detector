[[Delgadillo_et+al_FinsosentAdvancingFinancialMarketSentiment_2024]]

# [FinSoSent: Advancing Financial Market Sentiment Analysis through Pretrained Large Language Models](https://doi.org/10.3390/bdcc8080087)

## [[Josiel Delgadillo]]; [[Johnson Kinyua]]; [[Charles Mutigwe]]

## Abstract
Predicting the directions of financial markets has been performed using a variety of approaches, and the large volume of unstructured data generated by traders and other stakeholders on social media microblog platforms provides unique opportunities for analyzing financial markets using additional perspectives. Pretrained large language models (LLMs) have demonstrated very good performance on a variety of sentiment analysis tasks in different domains. However, it is known that sentiment analysis is a very domain-dependent NLP task that requires knowledge of the domain ontology, and this is particularly the case with the financial domain, which uses its own unique vocabulary. Recent developments in NLP and deep learning including LLMs have made it possible to generate actionable financial sentiments using multiple sources including financial news, company fundamentals, technical indicators, as well social media microblogs posted on platforms such as StockTwits and X (formerly Twitter). ==We developed a financial social media sentiment analyzer (FinSoSent), which is a domain-specific large language model for the financial domain that was pretrained on financial news articles and fine-tuned and tested using several financial social media corpora==. We conducted a large number of experiments using different learning rates, epochs, and batch sizes to yield the best performing model. ==Our model outperforms current state-of-the-art FSA models based on over 860 experiments, demonstrating the efficacy and effectiveness of FinSoSent==. We also conducted experiments using ensemble models comprising FinSoSent and the other current state-of-the-art FSA models used in this research, and a slight performance improvement was obtained based on majority voting. Based on the results obtained across all models in these experiments, the significance of this study is that it highlights the fact that, despite the recent advances of LLMs, sentiment analysis even in domain-specific contexts remains a difficult research problem.

## Key concepts
#natural_language_processing; #finding/sentiment_analysis; #sentiment_analysis; #finding/language_model; #language_model; #claim/social_media; #social_media; #large_language_models; #finding/BERT; #BERT

## Quote
> The FinSoSent model, a BERT-based sentiment analysis model, was developed and fine-tuned for sentiment analysis without preprocessing the text, and its performance was compared to other sentiment analyzers, showing marginal improvements.

## Key points
- The prediction of the price movement of global financial market trends, corporate earnings, and financial instruments such as stocks is considered to be a very challenging task because it depends on a multitude of complex factors
- Fundamental indicators assess the financial situation of a business and the intrinsic value of its stock by analyzing the data about the firm’s business model, and there are several key indicators such as earnings per share (EPS), the price-to-earnings ratio (P/E), free cash flow (FCF), the price-to-book ratio (P/B), return on equity (ROE), and the debt-to-equity ratio (D/E) [^1]
- We have experimented with a novel preprocessing step that uses generative text models to identify complex verbiage in social media into something that can be embedded and tokens that can be represented within the bidirectional encoder representations from transformers (BERT) vocabulary
- Using generative AI text models provides a set of benefits in addition to tradeoffs; the benefits include transforming the original text to be clearer concerning its context and expanding acronyms including ticker symbols. This process would be difficult with traditional natural language processing (NLP) preprocessing steps as it usually makes the input smaller and, sometimes, less understandable
- Goertzel discusses the limitation of large language models (LLMs) for NLP use cases; Goertzel mentioned that general models cannot outperform fine-tuned models in NLP use cases, but perform well across many NLP tasks
- The systems performed poorly with a wide range of average classification accuracies, which ranged from 40% to 71%; domain-specific approaches to sentiment analysis outperformed the general-purpose approaches with an improvement of 11%
- This is a benefit that can be leveraged in making it clearer to predict sentiment by reproducing the original text and providing additional context to acronyms, which may not be well understood by BERT’s vocabulary set


## Summary

### Introduction
The prediction of financial market trends is a challenging task due to the multitude of complex factors involved, including economic factors, fundamental indicators, technical indicators, and social media sentiments.
Recent developments in natural language processing (NLP) and deep learning have made it possible to generate actionable financial sentiments using multiple sources, including financial news, company fundamentals, technical indicators, and social media microblogs.

### Sentiment Analysis
Sentiment analysis in the financial domain is particularly challenging due to the unique vocabulary and jargon used in the field.
Domain-specific sentiment analysis is necessary to accurately analyze financial sentiments.
Pretrained large language models (LLMs) have demonstrated good performance on sentiment analysis tasks, but their performance can be further improved by pretraining on domain-specific corpora.
The FinSoSent model, a domain-specific LLM pretrained on financial news articles and fine-tuned on financial social media corpora, outperforms current state-of-the-art models in detecting the sentiment of social media posts.

### Model Development
The development of FinSoSent involved conducting a large number of experiments using different learning rates, epochs, and batch sizes to yield the best-performing model.
The model was compared to other state-of-the-art sentiment analyzers, including commercial sentiment analyzers, commercial generative AI models, academic sentiment analysis models, and open-source sentiment analyzers.
The results show that FinSoSent outperforms these models, but the model accuracy is in the 50-60% range, highlighting the difficulty of sentiment analysis in the financial domain.
The researchers experimented with different hyperparameters, including pretraining, fine-tuning, learning rate, and batch size, to develop a sentiment analyzer for financial texts in social media.
They found that selecting the right fine-tuning dataset, learning rate, and batch size was critical for performance.
They also explored techniques to handle imbalanced classification datasets, including ADASYN and SMOTE.

### Models
Several models have been developed for financial sentiment analysis, including FinBERT, which outperforms previous state-of-the-art models in financial question-answering applications, financial sentence boundary detection, and financial sentiment analysis.
Other models, such as PyFin-Sentiment, XLNet, ALBERT, DistilBERT, and BART, have also been developed to improve upon the limitations of BERT, including high computing demands and large memory needs.

### Datasets
Various datasets have been used for financial sentiment analysis, including FiQA Task 1 and FiQA Task 2, Financial PhraseBank, FinSBD Shared Task dataset, FinSoMe, SemEval-2017 Task 5, Fin-Lin, Sanders, and Taborda-L.
These datasets consist of financial texts from sources such as StockTwits, Twitter, and news articles, and have been annotated with sentiment labels.

### Methods
The FinSoSent model was developed using a pretrained BERT model and fine-tuned on several financial datasets.
The model was trained using a transformer architecture, which captures long-range dependencies and performs well for sentiment analysis.
The model was also preprocessed using techniques such as tokenization, stopword removal, and sentiment labeling.
The performance of the FinSoSent model was evaluated on several testing datasets, including Fin-Lin, Sanders, and Taborda-L.

### Dataset Creation
The researchers created a pretraining dataset by leveraging the Thomas Reuters Corpus, which allowed them to identify quality articles and extract long contiguous text.
They tokenized each article and evaluated the tokens for financial content, creating a dataset of 49 million words.
The dataset was compared to two other FinBERT models, one using FinancialWeb and YahooFinance data, and the other using SEC annual filing reports and analyst reports.

### Results And Analysis
The researchers conducted thorough experiments and error analysis to evaluate the performance of their FinSoSent model.
They found that the pretraining datasets used reached inconclusive results, with evidence of marginally better performance.
They also observed that finding the correct balance in the learning rate and batch size was essential for finding great increases in performance.
The error analysis showed that accurately, inaccurately, and severely inaccurately predicted documents had relatively the same structure across the tested datasets.

### Model Performance
The FinSoSent model outperforms other sentiment analyzers, including Amazon-Comprehend, FinBERT, GPT-3.5-Turbo, IBM WATSON, SentiStrength, and VADER, in terms of accuracy.
However, the difference in sentiment scores between models is marginal, indicating that improvements in this field are mostly marginal due to the complexity of the task.
Ensemble models using soft voting and majority voting techniques also provided a modest improvement in performance.

### Limitations And Challenges
The study notes several limitations, including the use of relatively small datasets, which could impact the results.
The model struggled to predict sentiments in texts with complex social media verbiage, multiple sentiments, and emotions of regret or humor.
Additionally, the model is only aware of the raw text it is presented and lacks understanding of additional information, such as the author's motivations or perspectives.

### Future Work
The study suggests several areas for future improvement, including the use of a model with larger parameters, exploring aspect-based sentiment analysis, and novel preprocessing steps using generative text models.
The use of generative AI models can transform complex verbiage into a more understandable form, but also introduces challenges such as hallucinations and lack of reproducibility.
The study proposes using a sentence similarity score, such as cosine similarity, to ensure the integrity of the original text.


## Study subjects

### 7 financial domain-specific datasets
- Datasets and Data PreparationThe FinSoSent model is a domain-specific sentiment analyzer. ==In this study, we used seven financial domain-specific datasets to pretrain, fine-tune, and test the model==. The datasets consist of Twitter and StockTwits posts that are related to the financial markets.Below, we describe these datasets and their application to the model-building process

### 3757384 financial tweets
- Their model was benchmarked against FinBERT [^28], VADER [^43], Twitter RoBERTa [^27], and NTUSD-Fin [^44]; their model outperforms these models on financial social media sentiment classification task results obtained using the FinSoMe and their own financial dataset. ==Their dataset was created by collecting 3,757,384 financial tweets on S&amp;P 500 tickers from Twitter from 1 April 2021 and 1 May 2022 that met certain criteria, then filtering and annotating them to end up with==. 2,755,824 tweets

## Data analysis
- #method/bert_model
- #method/finbert_model
- #method/finsosent_model
- #method/scibert_model
- #method/ibm_watsons_models

## Findings
- <mark class="claim">Our model outperforms current state-of-the-art FSA models based on over 860 experiments, demonstrating the efficacy and effectiveness of FinSoSent</mark>
- 2018, evaluated 28 state-of-the-art Twitter <a class="keyword" href="https://en.wikipedia.org/wiki/sentiment_analysis" title="sentiment analysis">sentiment analysis</a> systems across five domains (security, retail, technology, pharmaceuticals, and telecommunications) and found that the average classification accuracies of these systems ranged from 40% to 71%
- 28 state-of-the-art systems. They reported that the performance of these systems remains rather poor with tweet sentiment classification accuracies below 70%
- According to this study, the systems performed poorly with a wide range of average classification accuracies, <mark class="fact">which ranged from 40% to 71%</mark>; domain-specific approaches to <a class="keyword" href="https://en.wikipedia.org/wiki/sentiment_analysis" title="sentiment analysis">sentiment analysis</a> outperformed the general-purpose approaches with an improvement of 11%
- TRC2-financial, which is a subset of the Reuters dataset [^30], and then fine-tuned using the Financial PhraseBank dataset created by Malo et al [^31]. To validate their FinBERT, they implemented other pretrained <a class="keyword" href="https://en.wikipedia.org/wiki/language_model" title="language models">language models</a> using ELMo, LSTM, and ULMFit for financial <a class="keyword" href="https://en.wikipedia.org/wiki/sentiment_analysis" title="sentiment analysis">sentiment analysis</a> for comparison with FinBERT. Their FinBERT increased the classification accuracy by 15% compared with these other models
- <mark class="claim">While evaluating FinSoSent, we found, as shown in Tables 8 and 9, that using the largest epoch did not constitute the best performance, but rather, settling at around 50 epochs improved performance on average by 10% when compared <mark class="fact">to the 15 epoch training set for the weighted F1-score</mark></mark>

##  Builds on previous research
- The FinSoSent model outperforms some of the latest large language models (LLMs), such as, FinBERT and GPT3.5-Turbo 16K (released in June 2023), in detecting the sentiment of social media posts. However, the model accuracy is in the 50–60% range, which is ==in line with the findings by Zimbra et al== [^15], who, in August 2018, before the release of the BERT model in October.
- This domain-specific dataset, which we refer to as FinTRC2, was used to pretrain our model. ==A similar classification of documents in the TRC2 dataset by Araci== [^28] generated.
- The sentiment class distribution of the testing datasets is shown in Figure 2. For testing the FinSoSent model, as well as the other five comparative sentiment analyzers, ==we used the following four datasets: Fin-Lin (FL_ST): The parent dataset (Fin-Lin) consists of 3811 documents, comprised of microblogs from StockTwits, news articles from Yahoo! News, financial reports for publicly traded companies, and analyst reports from 1 July 2018 to 30 September 2018== [^54].
- In total, we were able to create a dataset of 49 million words. The ==different versions of FinBERT are briefly explained in Section 2, and we compared our approach to two of those FinBERT models, the FinBERT model by Liu et al== [^33] and the FinBERT model by Yang et al [^40].
- An alternative approach to preprocessing can be to leverage generative text large language models or LLMs, something we will continue to experiment with in future works. ==According to Balaji et al [^57], sentiment analysis has different classifications, which differ in granularity, from the document level down to more granular classifications like the phrase level==.

## Differs from previous work
- To combat this, we incorporated a sentence similarity score using the cosine similarity to compare the original text and the preprocessed text, ensuring the quality of the integrity of the original text; this is a widely used metric for comparing two texts and their similarity. ==This technique is used in search engines to compare a query with the search results; technically speaking, cosine similarity is comparing terms between documents; however, this does not include the semantic similarity of text, as elaborated by Rahutomo et al== [^70] and Raju et al [^71].

## Contributions
- This work developed a model called FinSoSent, which pretrained a BERT-based model and fine-tuned it downstream for sentiment analysis without preprocessing the text. We believe there is scope for more improvement in three different areas: the usage of a model with larger parameters, changing the scope of sentiment analysis, and a novel idea for preprocessing the input. Firstly, training a model on BERT-large will provide an increase in the number of encoders, bidirectional self-attention heads, and parameters; this may provide more robust and better understanding of the input documents. Secondly, we would also like to address an inherited problem with document-based sentiment analysis as discussed by Balaji et al [^57] and Hoang et al [^68], by exploring aspect-based sentiment analysis, which allows <mark class="fact">us to address the challenges of multiple sentiments being present in a document</mark>. Lastly, <mark class="fact">we have experimented with a novel preprocessing step that uses generative text models to identify complex verbiage in social media</mark> into something that can be embedded and <mark class="fact">tokens that can be represented within the BERT vocabulary</mark>. Figure 4 shows a social media post that was preprocessed using the novel idea mentioned earlier using GPT 3.5-turbo into a structured form that is more understandable.

## Limitations
- The limitations of the study include the fact that the accuracy of the model is in the 50-60% range, which is relatively low, and that the study only focuses on social media posts from Twitter and StockTwits.
- The study noted several limitations, including the small size of the datasets, the use of a manual step-by-step approach to select the optimal model, and the potential impact of the limitations of large language models on the results.


## References
[^1]: Financial Terms Dictionary. Investopedia. Available online: https://www.investopedia.com/financial-term-dictionary-4769738 (accessed on 30 November 2021).  [OA](https://www.investopedia.com/financial-term-dictionary-4769738)  

[^2]: Fama, E.F. Random Walks in Stock Market Prices. Financ. Anal. J. 1965, 21, 55–59. [CrossRef]  [OA](https://engine.scholarcy.com/oa_version?query=Fama%2C%20E.F.%20Random%20Walks%20in%20Stock%20Market%20Prices.%20Financ%201965&author=Fama&title=Random%20Walks%20in%20Stock%20Market%20Prices.%20Financ&year=1965) [GScholar](https://scholar.google.co.uk/scholar?q=Fama%2C%20E.F.%20Random%20Walks%20in%20Stock%20Market%20Prices.%20Financ%201965) [Scite](/scite_tallies?query=author%3AFama%2Ctitle%3ARandom%20Walks%20in%20Stock%20Market%20Prices.%20Financ%2Cyear%3A1965)

[^3]: Fama, E.F. Efficient Capital Markets: A Review of Theory and Empirical Work. J. Financ. 1970, 25, 383–417. [CrossRef]  [OA](https://engine.scholarcy.com/oa_version?query=Fama%2C%20E.F.%20Efficient%20Capital%20Markets%3A%20A%20Review%20of%20Theory%20and%20Empirical%20Work%201970&author=Fama&title=Efficient%20Capital%20Markets%3A%20A%20Review%20of%20Theory%20and%20Empirical%20Work&year=1970) [GScholar](https://scholar.google.co.uk/scholar?q=Fama%2C%20E.F.%20Efficient%20Capital%20Markets%3A%20A%20Review%20of%20Theory%20and%20Empirical%20Work%201970) [Scite](/scite_tallies?query=author%3AFama%2Ctitle%3AEfficient%20Capital%20Markets%3A%20A%20Review%20of%20Theory%20and%20Empirical%20Work%2Cyear%3A1970)

[^4]: Twitter, Inc. Available online: https://twitter.com/ (accessed on 30 November 2021).  [OA](https://twitter.com/)  

[^5]: StockTwits, Inc. Available online: https://stocktwits.com/ (accessed on 30 November 2021).  [OA](https://stocktwits.com/)  

[^6]: Wang, G.; Wang, T.; Wang, B.; Sambasivan, D.; Zhang, Z.; Zheng, H.; Zhao, B.Y. Crowds on Wall Street: Extracting value from collaborative investing platforms. In Proceedings of the 18th ACM Conference on Computer Supported Cooperative Work &amp; Social Computing, Vancouver, BC, Canada, 14–18 March 2015; pp. 17–30.  [OA](https://scholar.google.co.uk/scholar?q=Wang%2C%20G.%20Wang%2C%20T.%20Wang%2C%20B.%20Sambasivan%2C%20D.%20Crowds%20on%20Wall%20Street%3A%20Extracting%20value%20from%20collaborative%20investing%20platforms%202015-03-14) [GScholar](https://scholar.google.co.uk/scholar?q=Wang%2C%20G.%20Wang%2C%20T.%20Wang%2C%20B.%20Sambasivan%2C%20D.%20Crowds%20on%20Wall%20Street%3A%20Extracting%20value%20from%20collaborative%20investing%20platforms%202015-03-14) 

[^7]: Sohangir, S.; Petty, N.; Wang, D. Financial sentiment lexicon analysis. In Proceedings of the IEEE 12th IEEE International Conference on Semantic Computing (ICSC), Laguna Hills, CA, USA, 12 April 2018; pp. 286–289.  [OA](https://scholar.google.co.uk/scholar?q=Sohangir%2C%20S.%20Petty%2C%20N.%20Wang%2C%20D.%20Financial%20sentiment%20lexicon%20analysis%202018-04-12) [GScholar](https://scholar.google.co.uk/scholar?q=Sohangir%2C%20S.%20Petty%2C%20N.%20Wang%2C%20D.%20Financial%20sentiment%20lexicon%20analysis%202018-04-12) 

[^8]: Sohangir, S.; Wang, D.; Pomeranets, A.; Khoshgoftaar, T.M. Big data: Deep learning for financial sentiment analysis. J. Big Data 2018, 5, 3. [CrossRef]  [OA](https://engine.scholarcy.com/oa_version?query=Sohangir%2C%20S.%20Wang%2C%20D.%20Pomeranets%2C%20A.%20Khoshgoftaar%2C%20T.M.%20Big%20data%3A%20Deep%20learning%20for%20financial%20sentiment%20analysis%202018&author=Sohangir&title=Big%20data%3A%20Deep%20learning%20for%20financial%20sentiment%20analysis&year=2018) [GScholar](https://scholar.google.co.uk/scholar?q=Sohangir%2C%20S.%20Wang%2C%20D.%20Pomeranets%2C%20A.%20Khoshgoftaar%2C%20T.M.%20Big%20data%3A%20Deep%20learning%20for%20financial%20sentiment%20analysis%202018) [Scite](/scite_tallies?query=author%3ASohangir%2Ctitle%3ABig%20data%3A%20Deep%20learning%20for%20financial%20sentiment%20analysis%2Cyear%3A2018)

[^9]: Zhang, L.; Wang, S.; Liu, B. Deep learning for sentiment analysis: A survey. Wiley Interdiscip. Rev. Data Min. Knowl. Discov. 2018, 8, e1253. [CrossRef]  [OA](https://engine.scholarcy.com/oa_version?query=Zhang%2C%20L.%20Wang%2C%20S.%20Liu%2C%20B.%20Deep%20learning%20for%20sentiment%20analysis%3A%20A%20survey%202018&author=Zhang&title=Deep%20learning%20for%20sentiment%20analysis%3A%20A%20survey&year=2018) [GScholar](https://scholar.google.co.uk/scholar?q=Zhang%2C%20L.%20Wang%2C%20S.%20Liu%2C%20B.%20Deep%20learning%20for%20sentiment%20analysis%3A%20A%20survey%202018) [Scite](/scite_tallies?query=author%3AZhang%2Ctitle%3ADeep%20learning%20for%20sentiment%20analysis%3A%20A%20survey%2Cyear%3A2018)

[^10]: Zhao, L.; Li, L.; Zheng, X. A BERT Based Sentiment Analysis and Key Entity Detection Approach for Online Financial Texts. arXiv 2020, arXiv:2001.05326. [CrossRef]  [OA](https://arxiv.org/abs/2001.05326)  

[^11]: Cui, X.; Lam, D.; Verma, A. Embedded Value in Bloomberg News and Social Sentiment Data; Bloomberg, Technical Report. 2016. Available online: https://developer.twitter.com/content/dam/developer-twitter/pdfs-and-files/Bloomberg-Twitter-DataResearch-Report.pdf (accessed on 30 November 2021).  [OA](https://developer.twitter.com/content/dam/developer-twitter/pdfs-and-files/Bloomberg-Twitter-DataResearch-Report.pdf)  [Scite](/scite_tallies?query=author%3ACui%2Ctitle%3AEmbedded%20Value%20in%20Bloomberg%20News%20and%20Social%20Sentiment%20Data%3B%20Bloomberg%2Cyear%3A2016)

[^12]: Tetlock, T.C. Giving Content to Investor Sentiment: The Role of Media in the Stock Market. J. Financ. 2007, 62, 1139–1168. [CrossRef]  [OA](https://engine.scholarcy.com/oa_version?query=Tetlock%2C%20T.C.%20Giving%20Content%20to%20Investor%20Sentiment%3A%20The%20Role%20of%20Media%20in%20the%20Stock%20Market%202007&author=Tetlock&title=Giving%20Content%20to%20Investor%20Sentiment%3A%20The%20Role%20of%20Media%20in%20the%20Stock%20Market&year=2007) [GScholar](https://scholar.google.co.uk/scholar?q=Tetlock%2C%20T.C.%20Giving%20Content%20to%20Investor%20Sentiment%3A%20The%20Role%20of%20Media%20in%20the%20Stock%20Market%202007) [Scite](/scite_tallies?query=author%3ATetlock%2Ctitle%3AGiving%20Content%20to%20Investor%20Sentiment%3A%20The%20Role%20of%20Media%20in%20the%20Stock%20Market%2Cyear%3A2007)

[^13]: Tetlock, P.C.; Saar-Tsechansky, M.; Macskassy, S. More Than Words: Quantifying Language to Measure Firms’ Fundamentals. J. Financ. 2008, 63, 1437–1467. [CrossRef]  [OA](https://engine.scholarcy.com/oa_version?query=Tetlock%2C%20P.C.%20Saar-Tsechansky%2C%20M.%20Macskassy%2C%20S.%20More%20Than%20Words%3A%20Quantifying%20Language%20to%20Measure%20Firms%E2%80%99%20Fundamentals%202008&author=Tetlock&title=More%20Than%20Words%3A%20Quantifying%20Language%20to%20Measure%20Firms%E2%80%99%20Fundamentals&year=2008) [GScholar](https://scholar.google.co.uk/scholar?q=Tetlock%2C%20P.C.%20Saar-Tsechansky%2C%20M.%20Macskassy%2C%20S.%20More%20Than%20Words%3A%20Quantifying%20Language%20to%20Measure%20Firms%E2%80%99%20Fundamentals%202008) [Scite](/scite_tallies?query=author%3ATetlock%2Ctitle%3AMore%20Than%20Words%3A%20Quantifying%20Language%20to%20Measure%20Firms%E2%80%99%20Fundamentals%2Cyear%3A2008)

[^14]: Delgadillo, J.; Kinyua, J. D.; Mutigwe, C. A BERT-based Model for Financial Social Media Sentiment Analysis. In Proceedings of the International Conference on Applications of Sentiment Analysis (ICASA 2022), Cairo, Egypt, 15–16 December 2022.  [OA](https://scholar.google.co.uk/scholar?q=Delgadillo%2C%20J.%20Kinyua%2C%20J.D.%20Mutigwe%2C%20C.%20A%20BERT-based%20Model%20for%20Financial%20Social%20Media%20Sentiment%20Analysis%202022-12-15) [GScholar](https://scholar.google.co.uk/scholar?q=Delgadillo%2C%20J.%20Kinyua%2C%20J.D.%20Mutigwe%2C%20C.%20A%20BERT-based%20Model%20for%20Financial%20Social%20Media%20Sentiment%20Analysis%202022-12-15) 

[^15]: Zimbra, D.; Abbasi, A.; Zeng, D.; Chen, H. The State-of-the-Art in Twitter Sentiment Analysis: A Review and Benchmark Evaluation. ACM Trans. Manag. Inf. Syst. 2018, 9, 1–29. [CrossRef]  [OA](https://engine.scholarcy.com/oa_version?query=Zimbra%2C%20D.%20Abbasi%2C%20A.%20Zeng%2C%20D.%20Chen%2C%20H.%20The%20State-of-the-Art%20in%20Twitter%20Sentiment%20Analysis%3A%20A%20Review%20and%20Benchmark%20Evaluation%202018&author=Zimbra&title=The%20State-of-the-Art%20in%20Twitter%20Sentiment%20Analysis%3A%20A%20Review%20and%20Benchmark%20Evaluation&year=2018) [GScholar](https://scholar.google.co.uk/scholar?q=Zimbra%2C%20D.%20Abbasi%2C%20A.%20Zeng%2C%20D.%20Chen%2C%20H.%20The%20State-of-the-Art%20in%20Twitter%20Sentiment%20Analysis%3A%20A%20Review%20and%20Benchmark%20Evaluation%202018) [Scite](/scite_tallies?query=author%3AZimbra%2Ctitle%3AThe%20State-of-the-Art%20in%20Twitter%20Sentiment%20Analysis%3A%20A%20Review%20and%20Benchmark%20Evaluation%2Cyear%3A2018)

[^16]: Sun, C.; Shrivastava, A.; Singh, S.; Gupta, A. Revisiting Unreasonable Effectiveness of Data in Deep Learning Era. In Proceedings of the 2017 IEEE International Conference on Computer Vision, Venice, Italy, 22–29 October 2017; pp. 843–852.  [OA](https://scholar.google.co.uk/scholar?q=Sun%2C%20C.%20Shrivastava%2C%20A.%20Singh%2C%20S.%20Gupta%2C%20A.%20Revisiting%20Unreasonable%20Effectiveness%20of%20Data%20in%20Deep%20Learning%20Era%202017-10-22) [GScholar](https://scholar.google.co.uk/scholar?q=Sun%2C%20C.%20Shrivastava%2C%20A.%20Singh%2C%20S.%20Gupta%2C%20A.%20Revisiting%20Unreasonable%20Effectiveness%20of%20Data%20in%20Deep%20Learning%20Era%202017-10-22) 

[^17]: Devlin, J.; Chang, M.-W.; Lee, K.; Toutanova, K. BERT: Pretraining of Deep Bidirectional Transformers for Language Understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Minneapolis, MN, USA, 2–7 June 2019; Volume 1 (Long and Short Papers), pp. 4171–4186.  [OA](https://scholar.google.co.uk/scholar?q=Devlin%2C%20J.%20Chang%2C%20M.-W.%20Lee%2C%20K.%20Toutanova%2C%20K.%20BERT%3A%20Pretraining%20of%20Deep%20Bidirectional%20Transformers%20for%20Language%20Understanding%202019-06-02) [GScholar](https://scholar.google.co.uk/scholar?q=Devlin%2C%20J.%20Chang%2C%20M.-W.%20Lee%2C%20K.%20Toutanova%2C%20K.%20BERT%3A%20Pretraining%20of%20Deep%20Bidirectional%20Transformers%20for%20Language%20Understanding%202019-06-02) 

[^18]: Howard, J.; Ruder, S. Universal Language Model Fine-tuning for Text Classification. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, Melbourne, Australia, 15–20 July 2018; Volume 1: Long Papers, pp. 328–339.  [OA](https://scholar.google.co.uk/scholar?q=Howard%2C%20J.%20Ruder%2C%20S.%20Universal%20Language%20Model%20Fine-tuning%20for%20Text%20Classification%202018-07-15) [GScholar](https://scholar.google.co.uk/scholar?q=Howard%2C%20J.%20Ruder%2C%20S.%20Universal%20Language%20Model%20Fine-tuning%20for%20Text%20Classification%202018-07-15) 

[^19]: Peters, M. E.; Neumann, M.; Iyyer, M.; Gardner, M.; Clark, C.; Lee, K.; Zettlemoyer, L. Deep Contextualized Word Representations. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, New Orleans, LA, USA, 1–6 June 2018; Volume 1 (Long Papers), pp. 2227–2237.  [OA](https://scholar.google.co.uk/scholar?q=Peters%2C%20M.E.%20Neumann%2C%20M.%20Iyyer%2C%20M.%20Gardner%2C%20M.%20Deep%20Contextualized%20Word%20Representations%202018-06-01) [GScholar](https://scholar.google.co.uk/scholar?q=Peters%2C%20M.E.%20Neumann%2C%20M.%20Iyyer%2C%20M.%20Gardner%2C%20M.%20Deep%20Contextualized%20Word%20Representations%202018-06-01) 

[^20]: Radford, A.; Wu, J.; Child, R.; Luan, D.; Amodei, D.; Sutskever, I. Language models are unsupervised multitask learners. OpenAI Blog 2019, 1, 8.  [OA](https://engine.scholarcy.com/oa_version?query=Radford%2C%20A.%20Wu%2C%20J.%20Child%2C%20R.%20Luan%2C%20D.%20Language%20models%20are%20unsupervised%20multitask%20learners%202019&author=Radford&title=Language%20models%20are%20unsupervised%20multitask%20learners&year=2019) [GScholar](https://scholar.google.co.uk/scholar?q=Radford%2C%20A.%20Wu%2C%20J.%20Child%2C%20R.%20Luan%2C%20D.%20Language%20models%20are%20unsupervised%20multitask%20learners%202019) [Scite](/scite_tallies?query=author%3ARadford%2Ctitle%3ALanguage%20models%20are%20unsupervised%20multitask%20learners%2Cyear%3A2019)

[^21]: Beltagy, I.; Lo, K.; Cohan, A. SciBERT: A Pretrained Language Model for Scientific Text. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), Hong Kong, China, 3–7 November 2019; pp. 3615–3620.  [OA](https://scholar.google.co.uk/scholar?q=Beltagy%2C%20I.%20Lo%2C%20K.%20Cohan%2C%20A.%20SciBERT%3A%20A%20Pretrained%20Language%20Model%20for%20Scientific%20Text%202019-11-03) [GScholar](https://scholar.google.co.uk/scholar?q=Beltagy%2C%20I.%20Lo%2C%20K.%20Cohan%2C%20A.%20SciBERT%3A%20A%20Pretrained%20Language%20Model%20for%20Scientific%20Text%202019-11-03) 

[^22]: Lee, J.; Yoon, W.; Kim, S.; Kim, D.; Kim, S.; So, C. H.; Kang, J. BioBERT: A pretrained biomedical language representation model for biomedical text mining. Bioinformatics 2019, 36, 1234–1240. [CrossRef] [PubMed]  [OA](https://engine.scholarcy.com/oa_version?query=Lee%2C%20J.%20Yoon%2C%20W.%20Kim%2C%20S.%20Kim%2C%20D.%20BioBERT%3A%20A%20pretrained%20biomedical%20language%20representation%20model%20for%20biomedical%20text%20mining%202019&author=Lee&title=BioBERT%3A%20A%20pretrained%20biomedical%20language%20representation%20model%20for%20biomedical%20text%20mining&year=2019) [GScholar](https://scholar.google.co.uk/scholar?q=Lee%2C%20J.%20Yoon%2C%20W.%20Kim%2C%20S.%20Kim%2C%20D.%20BioBERT%3A%20A%20pretrained%20biomedical%20language%20representation%20model%20for%20biomedical%20text%20mining%202019) [Scite](/scite_tallies?query=author%3ALee%2Ctitle%3ABioBERT%3A%20A%20pretrained%20biomedical%20language%20representation%20model%20for%20biomedical%20text%20mining%2Cyear%3A2019)

[^23]: Huang, K.; Altosaar, J.; Ranganath, R. ClinicalBERT: Modeling clinical notes and predicting hospital readmission. arXiv 2019, arXiv:1904.05342.  [OA](https://arxiv.org/abs/1904.05342)  

[^24]: Agaian, S.; Kolm, P. Financial sentiment analysis using machine learning techniques. Int. J. Invest. Manag. Financ. Innov. 2017, 3, 1–9.  [OA](https://engine.scholarcy.com/oa_version?query=Agaian%2C%20S.%20Kolm%2C%20P.%20Financial%20sentiment%20analysis%20using%20machine%20learning%20techniques%202017&author=Agaian&title=Financial%20sentiment%20analysis%20using%20machine%20learning%20techniques&year=2017) [GScholar](https://scholar.google.co.uk/scholar?q=Agaian%2C%20S.%20Kolm%2C%20P.%20Financial%20sentiment%20analysis%20using%20machine%20learning%20techniques%202017) [Scite](/scite_tallies?query=author%3AAgaian%2Ctitle%3AFinancial%20sentiment%20analysis%20using%20machine%20learning%20techniques%2Cyear%3A2017)

[^25]: Man, X.; Luo, T.; Lin, J. Financial Sentiment Analysis (FSA): A Survey. In Proceedings of the IEEE International Conference on Industrial Cyber Physical Systems (ICPS), Taipei, Taiwan, 6–9 May 2019; pp. 617–622.  [OA](https://scholar.google.co.uk/scholar?q=Man%2C%20X.%20Luo%2C%20T.%20Lin%2C%20J.%20Financial%20Sentiment%20Analysis%20%28FSA%29%3A%20A%20Survey%202019-05-06) [GScholar](https://scholar.google.co.uk/scholar?q=Man%2C%20X.%20Luo%2C%20T.%20Lin%2C%20J.%20Financial%20Sentiment%20Analysis%20%28FSA%29%3A%20A%20Survey%202019-05-06) 

[^26]: Yang, S.; Rosenfeld, J.; Makutonin, J. Financial aspect-based sentiment analysis using deep representations. arXiv 2018, arXiv:1808.07931. Available online: http://arxiv.org/abs/1808.07931 (accessed on 30 November 2021).  [OA](http://arxiv.org/abs/1808.07931)  

[^27]: Liu, Y.; Ott, M.; Goyal, N.; Du, J.; Joshi, M.; Chen, D.; Levy, O.; Lewis, M.; Zettlemoyer, L.; Stoyanov, V. RoBERTa: A Robustly Optimized BERT Pretraining Approach. arXiv 2019, arXiv:1907.11692. Available online: http://arxiv.org/abs/1907.11692 (accessed on 30 November 2021).  [OA](http://arxiv.org/abs/1907.11692)  

[^28]: Araci, D. FinBERT: Financial Sentiment Analysis with Pretrained Language Models. arXiv 2019, arXiv:1908.10063. Available online: http://arxiv.org/abs/1908.10063 (accessed on 30 November 2021).  [OA](http://arxiv.org/abs/1908.10063)  

[^29]: Araci, D.T.; Zulkuf Genc, Z. FinBERT: Financial Sentiment Analysis with BERT. Prosus AI Tech Blog. 2020. Available online: https://medium.com/prosus-ai-tech-blog/finbert-financial-sentiment-analysis-with-bert-b277a3607101 (accessed on 1 July 2022).  [OA](https://medium.com/prosus-ai-tech-blog/finbert-financial-sentiment-analysis-with-bert-b277a3607101)  

[^30]: Reuters Corpora (RCV1, RCV2, TRC2). National Institute of Standards and Technology. 2004. Available online: https://trec.nist.gov/data/reuters/reuters.html (accessed on 6 April 2023).31. Malo, P.; Sinha, A.; Korhonen, P.; Wallenius, J.; Takala, P. Good debt or bad debt: Detecting semantic orientations in economic texts. J. Assoc. Inf. Sci. Technol. 2014, 65, 782–796. [CrossRef]  [OA](https://trec.nist.gov/data/reuters/reuters.html)  [Scite](/scite_tallies?query=author%3ACorpora%2Ctitle%3ATRC2%2Cyear%3A2004)

[^32]: Desola, V.; Hanna, K.; Nonis, P. FinBERT: Pretrained Model on SEC Filings for Financial Natural Language Tasks; Technical Report; University of California: Los Angeles, CA, USA, 2019.  [OA](https://scholar.google.co.uk/scholar?q=Desola%2C%20V.%20Hanna%2C%20K.%20Nonis%2C%20P.%20FinBERT%3A%20Pretrained%20Model%20on%20SEC%20Filings%20for%20Financial%20Natural%20Language%20Tasks%3B%20Technical%20Report%202019) [GScholar](https://scholar.google.co.uk/scholar?q=Desola%2C%20V.%20Hanna%2C%20K.%20Nonis%2C%20P.%20FinBERT%3A%20Pretrained%20Model%20on%20SEC%20Filings%20for%20Financial%20Natural%20Language%20Tasks%3B%20Technical%20Report%202019) 

[^33]: Liu, Z.; Huang, D.; Huang, K.; Li, Z.; Zhao, J. FinBERT: A Pretrained Financial Language Representation Model for Financial Text Mining. In Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence (IJCAI-20), Virtual, 7–15 January 2021; pp. 4513–4519.  [OA](https://scholar.google.co.uk/scholar?q=Liu%2C%20Z.%20Huang%2C%20D.%20Huang%2C%20K.%20Li%2C%20Z.%20FinBERT%3A%20A%20Pretrained%20Financial%20Language%20Representation%20Model%20for%20Financial%20Text%20Mining%202021-01) [GScholar](https://scholar.google.co.uk/scholar?q=Liu%2C%20Z.%20Huang%2C%20D.%20Huang%2C%20K.%20Li%2C%20Z.%20FinBERT%3A%20A%20Pretrained%20Financial%20Language%20Representation%20Model%20for%20Financial%20Text%20Mining%202021-01) 

[^34]: Common Crawl. Available online: https://commoncrawl.org/ (accessed on 30 November 2021).  [OA](https://commoncrawl.org/)  

[^35]: FinancialWeb. Available online: https://www.finweb.com/ (accessed on 30 November 2021).  [OA](https://www.finweb.com/)  

[^36]: Yahoo! Finance. Available online: https://finance.yahoo.com/ (accessed on 30 November 2021).  [OA](https://finance.yahoo.com/)  

[^37]: Reddit. Available online: https://www.reddit.com/ (accessed on 30 November 2021).  [OA](https://www.reddit.com/)  

[^38]: Financial Opinion Mining and Question Answering. 2017. Available online: https://sites.google.com/view/fiqa/ (accessed on 30 November 2021).  [OA](https://sites.google.com/view/fiqa/)  

[^39]: The First Workshop on Financial Technology and Natural Language Processing (FinNLP) with a Shared Task for Sentence Boundary Detection in PDF Noisy Text in the Financial Domain (FinSBD). [n. d.]. Available online: https://sites.google.com/nlg.csie.ntu.edu.tw/finnlp/ (accessed on 30 November 2021).  [OA](https://sites.google.com/nlg.csie.ntu.edu.tw/finnlp/)  

[^40]: Yang, Y.; UY, M.C.S.; Huang, A. FinBERT: A Pretrained Language Model for Financial Communications. arXiv 2020, arXiv:2006.08097. Available online: https://arxiv.org/abs/2006.08097 (accessed on 30 November 2021).  [OA](https://arxiv.org/abs/2006.08097)  

[^41]: Huang, A.H.; Zang, A.Y.; Zheng, R. Evidence on the Information Content of Text in Analyst Reports. Account. Rev. 2014, 89, 6, 2151–2180. [CrossRef]  [OA](https://engine.scholarcy.com/oa_version?query=Huang%2C%20A.H.%20Zang%2C%20A.Y.%20Zheng%2C%20R.%20Evidence%20on%20the%20Information%20Content%20of%20Text%20in%20Analyst%20Reports%202014&author=Huang&title=Evidence%20on%20the%20Information%20Content%20of%20Text%20in%20Analyst%20Reports&year=2014) [GScholar](https://scholar.google.co.uk/scholar?q=Huang%2C%20A.H.%20Zang%2C%20A.Y.%20Zheng%2C%20R.%20Evidence%20on%20the%20Information%20Content%20of%20Text%20in%20Analyst%20Reports%202014) [Scite](/scite_tallies?query=author%3AHuang%2Ctitle%3AEvidence%20on%20the%20Information%20Content%20of%20Text%20in%20Analyst%20Reports%2Cyear%3A2014)

[^42]: Wilksch, M.; Abramova, O. PyFin-sentiment: Towards a machine-learning-based model for deriving sentiment from financial tweets. Int. J. Inf. Manag. Data Insights 2023, 3, 1, 100171. [CrossRef]  [OA](https://engine.scholarcy.com/oa_version?query=Wilksch%2C%20M.%20Abramova%2C%20O.%20PyFin-sentiment%3A%20Towards%20a%20machine-learning-based%20model%20for%20deriving%20sentiment%20from%20financial%20tweets%202023&author=Wilksch&title=PyFin-sentiment%3A%20Towards%20a%20machine-learning-based%20model%20for%20deriving%20sentiment%20from%20financial%20tweets&year=2023) [GScholar](https://scholar.google.co.uk/scholar?q=Wilksch%2C%20M.%20Abramova%2C%20O.%20PyFin-sentiment%3A%20Towards%20a%20machine-learning-based%20model%20for%20deriving%20sentiment%20from%20financial%20tweets%202023) [Scite](/scite_tallies?query=author%3AWilksch%2Ctitle%3APyFin-sentiment%3A%20Towards%20a%20machine-learning-based%20model%20for%20deriving%20sentiment%20from%20financial%20tweets%2Cyear%3A2023)

[^43]: Hutto, C.; Gilbert, E. VADER: A Parsimonious Rule Based Model for Sentiment Analysis of Social Media Text. In Proceedings of the International AAAI Conference on Web and Social Media, Ann Arbor, MI, USA, 1–4 June 2014; pp. 216–225.  [OA](https://scholar.google.co.uk/scholar?q=Hutto%2C%20C.%20Gilbert%2C%20E.%20VADER%3A%20A%20Parsimonious%20Rule%20Based%20Model%20for%20Sentiment%20Analysis%20of%20Social%20Media%20Text%202014-06-01) [GScholar](https://scholar.google.co.uk/scholar?q=Hutto%2C%20C.%20Gilbert%2C%20E.%20VADER%3A%20A%20Parsimonious%20Rule%20Based%20Model%20for%20Sentiment%20Analysis%20of%20Social%20Media%20Text%202014-06-01) 

[^44]: Chen, C.-C.; Huang, H.-H.; Chen, H.-H. NTUSD-Fin: A market sentiment dictionary for financial social media data applications. In Proceedings of the 1st Financial Narrative Processing Workshop (FNP 2018), Miyazaki, Japan, 7–12 May 2018; pp. 37–43.  [OA](https://scholar.google.co.uk/scholar?q=Chen%2C%20C.-C.%20Huang%2C%20H.-H.%20Chen%2C%20H.-H.%20NTUSD-Fin%3A%20A%20market%20sentiment%20dictionary%20for%20financial%20social%20media%20data%20applications%202018-05-07) [GScholar](https://scholar.google.co.uk/scholar?q=Chen%2C%20C.-C.%20Huang%2C%20H.-H.%20Chen%2C%20H.-H.%20NTUSD-Fin%3A%20A%20market%20sentiment%20dictionary%20for%20financial%20social%20media%20data%20applications%202018-05-07) 

[^45]: Yang, Z.; Dai, Z.; Yang, Y.; Carbonell, J.; Salakhutdinov, R.; Lee, Q.V. XLNet: Generalized Autoregressive Pretraining for Language Understanding. In Proceedings of the 33rd International Conference on Neural Information Processing Systems (NeurIPS 2019), Vancouver, BC, Canada, 8–14 December 2019; pp. 5753–5763.  [OA](https://scholar.google.co.uk/scholar?q=Yang%2C%20Z.%20Dai%2C%20Z.%20Yang%2C%20Y.%20Carbonell%2C%20J.%20XLNet%3A%20Generalized%20Autoregressive%20Pretraining%20for%20Language%20Understanding%202019-12-08) [GScholar](https://scholar.google.co.uk/scholar?q=Yang%2C%20Z.%20Dai%2C%20Z.%20Yang%2C%20Y.%20Carbonell%2C%20J.%20XLNet%3A%20Generalized%20Autoregressive%20Pretraining%20for%20Language%20Understanding%202019-12-08) 

[^46]: Lan, Z.; Chen, M.; Goodman, S.; Gimpel, K.; Sharma, P.; Soricut, R. ALBERT: A Lite BERT for Self-Supervised Learning of Language Representations. arXiv 2019, arXiv:1909.11942. Available online: http://arxiv.org/abs/1909.11942 (accessed on 30 November 2021).  [OA](http://arxiv.org/abs/1909.11942)  

[^47]: Sanh, V.; Debut, L.; Chaumond, J.; Wolf, T. DistilBERT, a Distilled Version of BERT: Smaller, Faster, Cheaper and Lighter. arXiv 2019, arXiv:1910.01108. Available online: http://arxiv.org/abs/1910.01108 (accessed on 30 November 2021).  [OA](http://arxiv.org/abs/1910.01108)  

[^48]: Lewis, M.; Liu, Y.; Goyal, N.; Ghazvininejad, M.; Mohamed, A.; Levy, O.; Stoyanov, V.; Zettlemoyer, L. BART: Denoising Sequenceto-Sequence Pretraining for Natural Language Generation, Translation, and Comprehension. arXiv 2019, arXiv:1910.13461. Available online: http://arxiv.org/abs/1910.13461 (accessed on 30 November 2021).  [OA](http://arxiv.org/abs/1910.13461)  

[^49]: Mishev, K.; Gjorgjevikj, A.; Vodenska, I.; Chitkushev, L.T.; Trajanov, D. Evaluation of Sentiment Analysis in Finance: From Lexicons to Transformers. IEEE Access 2020, 8, 131662–131682. [CrossRef]  [OA](https://engine.scholarcy.com/oa_version?query=Mishev%2C%20K.%20Gjorgjevikj%2C%20A.%20Vodenska%2C%20I.%20Chitkushev%2C%20L.T.%20Evaluation%20of%20Sentiment%20Analysis%20in%20Finance%3A%20From%20Lexicons%20to%20Transformers%202020&author=Mishev&title=Evaluation%20of%20Sentiment%20Analysis%20in%20Finance%3A%20From%20Lexicons%20to%20Transformers&year=2020) [GScholar](https://scholar.google.co.uk/scholar?q=Mishev%2C%20K.%20Gjorgjevikj%2C%20A.%20Vodenska%2C%20I.%20Chitkushev%2C%20L.T.%20Evaluation%20of%20Sentiment%20Analysis%20in%20Finance%3A%20From%20Lexicons%20to%20Transformers%202020) [Scite](/scite_tallies?query=author%3AMishev%2Ctitle%3AEvaluation%20of%20Sentiment%20Analysis%20in%20Finance%3A%20From%20Lexicons%20to%20Transformers%2Cyear%3A2020)

[^50]: Bartunov, O.; Sigaev, T. Full-Text Search in PostgreSQL—Gentle Introduction; Technical Report; Moscow University: Moscow, Russia, 2007.  [OA](https://scholar.google.co.uk/scholar?q=Bartunov%2C%20O.%20Sigaev%2C%20T.%20Full-Text%20Search%20in%20PostgreSQL%E2%80%94Gentle%20Introduction%3B%20Technical%20Report%202007) [GScholar](https://scholar.google.co.uk/scholar?q=Bartunov%2C%20O.%20Sigaev%2C%20T.%20Full-Text%20Search%20in%20PostgreSQL%E2%80%94Gentle%20Introduction%3B%20Technical%20Report%202007) 

[^51]: Gaillat, T.; Zarrouk, M.; Freitas, A.; Davis, B. The SSIX Corpora: Three Gold Standard Corpora for Sentiment Analysis in English, Spanish and German Financial Microblogs. In Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018), Miyazaki, Japan; 7–12 May 2018; pp. 2671–2675.  [OA](https://scholar.google.co.uk/scholar?q=Gaillat%2C%20T.%20Zarrouk%2C%20M.%20Freitas%2C%20A.%20Davis%2C%20B.%20The%20SSIX%20Corpora%3A%20Three%20Gold%20Standard%20Corpora%20for%20Sentiment%20Analysis%20in%20English%2C%20Spanish%20and%20German%20Financial%20Microblogs%202018-05-07) [GScholar](https://scholar.google.co.uk/scholar?q=Gaillat%2C%20T.%20Zarrouk%2C%20M.%20Freitas%2C%20A.%20Davis%2C%20B.%20The%20SSIX%20Corpora%3A%20Three%20Gold%20Standard%20Corpora%20for%20Sentiment%20Analysis%20in%20English%2C%20Spanish%20and%20German%20Financial%20Microblogs%202018-05-07) 

[^52]: Chen, C.-C.; Huang, H.-H.; Chen, H.-H. Issues and Perspectives from 10,000 Annotated Financial Social Media Data. In Proceedings of the 12th Language Resources and Evaluation Conference, Marseille, France, 11–16 May 2020; pp. 6106–6110.  [OA](https://scholar.google.co.uk/scholar?q=Chen%2C%20C.-C.%20Huang%2C%20H.-H.%20Chen%2C%20H.-H.%20Issues%20and%20Perspectives%20from%2010%2C000%20Annotated%20Financial%20Social%20Media%20Data%202020-05-11) [GScholar](https://scholar.google.co.uk/scholar?q=Chen%2C%20C.-C.%20Huang%2C%20H.-H.%20Chen%2C%20H.-H.%20Issues%20and%20Perspectives%20from%2010%2C000%20Annotated%20Financial%20Social%20Media%20Data%202020-05-11) 

[^53]: SemEval-2017 Task 5: Fine-Grained Sentiment Analysis on Financial Microblogs and News. Available online: https://alt.qcri.org/semeval2017/task5/ (accessed on 30 November 2021).  [OA](https://alt.qcri.org/semeval2017/task5/)  

[^54]: Daudert, T. A Multi-Source Entity-Level Sentiment Corpus for the Financial Domain: The Fin-Lin Corpus. arXiv 2020, arXiv:2003.04073. Available online: http://arxiv.org/abs/2003.04073 (accessed on 30 November 2021).  [OA](http://arxiv.org/abs/2003.04073)  

[^55]: Saif, H.; Fernández, M.; He, Y.; Alani, H. Evaluation datasets for Twitter sentiment analysis: a survey and a new dataset, the STS-Gold. In Proceedings of the 1st International Workshop on Emotion and Sentiment in Social and Expressive Media: Approaches and Perspectives from AI (ESSEM 2013), Turin, Italy, 3 December 2013.  [OA](https://scholar.google.co.uk/scholar?q=Saif%2C%20H.%20Fern%C3%A1ndez%2C%20M.%20He%2C%20Y.%20Alani%2C%20H.%20Evaluation%20datasets%20for%20Twitter%20sentiment%20analysis%3A%20a%20survey%20and%20a%20new%20dataset%2C%20the%20STS-Gold%202013-12-03) [GScholar](https://scholar.google.co.uk/scholar?q=Saif%2C%20H.%20Fern%C3%A1ndez%2C%20M.%20He%2C%20Y.%20Alani%2C%20H.%20Evaluation%20datasets%20for%20Twitter%20sentiment%20analysis%3A%20a%20survey%20and%20a%20new%20dataset%2C%20the%20STS-Gold%202013-12-03) 

[^56]: Taborda, B.; de Almeida, A.; Dias, J.C.; Batista, F.; Ribeiro, R. Stock Market Tweets Data. IEEE Dataport 2021. [CrossRef]  [OA](https://engine.scholarcy.com/oa_version?query=Taborda%2C%20B.%20Almeida%2C%20A.%20Dias%2C%20J.C.%20Batista%2C%20F.%20Stock%20Market%20Tweets%20Data%202021&author=Taborda&title=Stock%20Market%20Tweets%20Data&year=2021) [GScholar](https://scholar.google.co.uk/scholar?q=Taborda%2C%20B.%20Almeida%2C%20A.%20Dias%2C%20J.C.%20Batista%2C%20F.%20Stock%20Market%20Tweets%20Data%202021) [Scite](/scite_tallies?query=author%3ATaborda%2Ctitle%3AStock%20Market%20Tweets%20Data%2Cyear%3A2021)

[^57]: Balaji, P.; Nagaraju, O.; Haritha, D. Levels of Sentiment Analysis and its Challenges: A Literature Review. In Proceedings of the International Conference of Big Data Analytics and Computational Intelligence (ICBDAC), Chirala, India, 23–25 March 2017; pp. 400–403.  [OA](https://scholar.google.co.uk/scholar?q=Balaji%2C%20P.%20Nagaraju%2C%20O.%20Haritha%2C%20D.%20Levels%20of%20Sentiment%20Analysis%20and%20its%20Challenges%3A%20A%20Literature%20Review%202017-03-23) [GScholar](https://scholar.google.co.uk/scholar?q=Balaji%2C%20P.%20Nagaraju%2C%20O.%20Haritha%2C%20D.%20Levels%20of%20Sentiment%20Analysis%20and%20its%20Challenges%3A%20A%20Literature%20Review%202017-03-23) 

[^58]: Chawla, N.V.; Bowyer, K.W.; Hall, L.O.; Kegelmeyer, W.P. SMOTE: Synthetic Minority Over-sampling Technique. J. Artif. Intell. Res. 2002, 16, 321–357. [CrossRef]  [OA](https://engine.scholarcy.com/oa_version?query=Chawla%2C%20N.V.%20Bowyer%2C%20K.W.%20Hall%2C%20L.O.%20Kegelmeyer%2C%20W.P.%20SMOTE%3A%20Synthetic%20Minority%20Over-sampling%20Technique%202002&author=Chawla&title=SMOTE%3A%20Synthetic%20Minority%20Over-sampling%20Technique&year=2002) [GScholar](https://scholar.google.co.uk/scholar?q=Chawla%2C%20N.V.%20Bowyer%2C%20K.W.%20Hall%2C%20L.O.%20Kegelmeyer%2C%20W.P.%20SMOTE%3A%20Synthetic%20Minority%20Over-sampling%20Technique%202002) [Scite](/scite_tallies?query=author%3AChawla%2Ctitle%3ASMOTE%3A%20Synthetic%20Minority%20Over-sampling%20Technique%2Cyear%3A2002)

[^59]: He, H.; Bai, Y.; Garcia, E.A.; Li, S. ADASYN: Adaptive synthetic sampling approach for imbalance learning. In Proceedings of the 2008 IEEE International Conference on Neural Networks (IJCNN 2008), Hong Kong, China, 1–8 June 2008; pp. 1322–1328.  [OA](https://scholar.google.co.uk/scholar?q=He%2C%20H.%20Bai%2C%20Y.%20Garcia%2C%20E.A.%20Li%2C%20S.%20ADASYN%3A%20Adaptive%20synthetic%20sampling%20approach%20for%20imbalance%20learning%202008-06-01) [GScholar](https://scholar.google.co.uk/scholar?q=He%2C%20H.%20Bai%2C%20Y.%20Garcia%2C%20E.A.%20Li%2C%20S.%20ADASYN%3A%20Adaptive%20synthetic%20sampling%20approach%20for%20imbalance%20learning%202008-06-01) 

[^60]: Li, X.; Wang, X.; Liu, H. Research on fine-tuning strategy of sentiment analysis model based on BERT. In Proceedings of the 2021 IEEE 3rd International Conference on Communications, Information System and Computer Engineering (CISCE), Beijing, China, 14–16 May 2021; pp. 798–802.  [OA](https://scholar.google.co.uk/scholar?q=Li%2C%20X.%20Wang%2C%20X.%20Liu%2C%20H.%20Research%20on%20fine-tuning%20strategy%20of%20sentiment%20analysis%20model%20based%20on%20BERT%202021-05-14) [GScholar](https://scholar.google.co.uk/scholar?q=Li%2C%20X.%20Wang%2C%20X.%20Liu%2C%20H.%20Research%20on%20fine-tuning%20strategy%20of%20sentiment%20analysis%20model%20based%20on%20BERT%202021-05-14) 

[^61]: Popel, M.; Bojar, O. Training Tips for the Transformer Model. arXiv 2018, arXiv:1804.00247. Available online: https://arxiv.org/pdf/1804.00247.pdf (accessed on 25 June 2022).  [OA](https://arxiv.org/pdf/1804.00247.pdf)  

[^62]: Amazon Web Services. Amazon Comprehend: Features. Available online: https://aws.amazon.com/comprehend/features (accessed on 25 June 2022).  [OA](https://aws.amazon.com/comprehend/features)  

[^63]: Amazon Web Services. Amazon Comprehend Developer Guide. Available online: https://docs.aws.amazon.com/comprehend/latest/dg/comprehend-dg.pdf.how-sentiment (accessed on 25 June 2022).  [OA](https://docs.aws.amazon.com/comprehend/latest/dg/comprehend-dg.pdf.how-sentiment)  

[^64]: OpenAI, GPT-3.5 Turbo. Available online: https://platform.openai.com/docs/models/gpt-3-5-turbo (accessed on 15 March 2024).  [OA](https://platform.openai.com/docs/models/gpt-3-5-turbo)  

[^65]: IBM Cloud API Docs: Natural Language Understanding. Available online: https://cloud.ibm.com/apidocs/natural-languageunderstanding?code=python (accessed on 25 June 2022).  [OA](https://cloud.ibm.com/apidocs/natural-languageunderstanding?code=python)  

[^66]: IBM. Watson Natural Language Understanding: Features. Available online: https://www.ibm.com/cloud/watson-naturallanguage-understanding/details (accessed on 25 June 2022).  [OA](https://www.ibm.com/cloud/watson-naturallanguage-understanding/details)  

[^67]: SentiStrength. Available online: http://sentistrength.wlv.ac.uk/ (accessed on 25 June 2022).  [OA](http://sentistrength.wlv.ac.uk/)  

[^68]: Hoang, M.; Bihorac, O. A.; Rouces, J. Aspect-Based Sentiment Analysis using BERT. In Proceedings of the 22nd Nordic Conference on Computational Linguistics, Turku, Finland, 30 September–2 October 2019; pp. 187–196. Available online: https://aclanthology.org/W19-6120/ (accessed on 30 November 2021).  [OA](https://aclanthology.org/W19-6120/)  

[^69]: Goertzel, B. Generative AI vs. AGI: The Cognitive Strengths and Weaknesses of Modern LLMs. 2023. Available online: https://arxiv.org/pdf/2309.10371.pdf (accessed on 25 June 2022).  [OA](https://arxiv.org/pdf/2309.10371.pdf)  

[^70]: Rahutomo, F.; Kitasuka, T.; Aritsugi, M. Semantic Cosine Similarity. In Proceedings of the 7th International Student Conference on Advanced Science and Technology, Seoul, Republic of Korea, 29–30 October 2012. Available online: https://www.researchgate.net/publication/262525676_Semantic_Cosine_Similarity (accessed on 30 November 2021).  [OA](https://www.researchgate.net/publication/262525676_Semantic_Cosine_Similarity)  

[^71]: Nora Raju, T.; Rahana, P.A.; Moncy, R.; Ajay, S.; Nambiar, S.K. Sentence Similarity—A State of Art Approaches. In Proceedings of the International Conference on Computing, Communication, Security and Intelligent Systems (IC3SIS), Kochi, India, 23–25 June 2022; pp. 1–6.   [OA](https://scholar.google.co.uk/scholar?q=Nora%20Raju%2C%20T.%20Rahana%2C%20P.A.%20Moncy%2C%20R.%20Ajay%2C%20S.%20Sentence%20Similarity%E2%80%94A%20State%20of%20Art%20Approaches%202022-06-23) [GScholar](https://scholar.google.co.uk/scholar?q=Nora%20Raju%2C%20T.%20Rahana%2C%20P.A.%20Moncy%2C%20R.%20Ajay%2C%20S.%20Sentence%20Similarity%E2%80%94A%20State%20of%20Art%20Approaches%202022-06-23) 

